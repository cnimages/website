<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>KubeSphere | The Kubernetes platform tailored for hybrid multicloud on </title>
    <link>https://cnimages.github.io/website/</link>
    <description>Recent content in KubeSphere | The Kubernetes platform tailored for hybrid multicloud on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    
	<atom:link href="https://cnimages.github.io/website/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Workspace Overview</title>
      <link>https://cnimages.github.io/website/docs/workspace-administration/workspace-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/workspace-administration/workspace-overview/</guid>
      <description>A workspace is a logical unit to organize your projects and DevOps projects and manage app templates and app repositories. It is the place for you to control resource access and share resources within your team in a secure way.
It is a best practice to create a new workspace for tenants (excluding cluster administrators). A same tenant can work in multiple workspaces, while a workspace allows multiple tenants to access it in different ways.</description>
    </item>
    
    <item>
      <title>Release Notes For 3.0.0</title>
      <link>https://cnimages.github.io/website/docs/release/release-v300/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/release/release-v300/</guid>
      <description>How to get v3.0.0  Install KubeSphere v3.0.0 on Linux Install KubeSphere v3.0.0 on existing Kubernetes  Release Notes Installer FEATURES  A brand-new installer: KubeKey, v1.0.0, which is a turnkey solution to installing Kubernetes with KubeSphere on different platforms. It is more easy to use and reduces the dependency on OS environment  UPGRADES &amp;amp; ENHANCEMENTS  Be compatible with Kubernetes 1.15.x, 1.16.x, 1.17.x and 1.18.x for ks-installer, v3.0.0 KubeKey officially supports Kubernetes 1.</description>
    </item>
    
    <item>
      <title>Upload Helm-based Applications</title>
      <link>https://cnimages.github.io/website/docs/workspace-administration/upload-helm-based-application/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/workspace-administration/upload-helm-based-application/</guid>
      <description>KubeSphere provides full lifecycle management for applications. Among others, workspace administrators can upload or create new app templates and test them quickly. Furthermore, they publish well-tested apps to App Store so that other users can deploy them with one click. To develop app templates, workspace administrators need to upload packaged Helm charts to KubeSphere first.
This tutorial demonstrates how to develop an app template by uploading a packaged Helm chart.</description>
    </item>
    
    <item>
      <title>Import Helm Repository</title>
      <link>https://cnimages.github.io/website/docs/workspace-administration/app-repository/import-helm-repository/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/workspace-administration/app-repository/import-helm-repository/</guid>
      <description>KubeSphere builds app repositories that allow users to use Kubernetes applications based on Helm charts. App repositories are powered by OpenPitrix, an open-source platform for cross-cloud application management sponsored by QingCloud. In an app repository, every application serves as a base package library. To deploy and manage an app from an app repository, you need to create the repository in advance.
To create a repository, you use an HTTP/HTTPS server or object storage solutions to store packages.</description>
    </item>
    
    <item>
      <title>Persistent Volume and Storage Class</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/persistent-volume-and-storage-class/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/persistent-volume-and-storage-class/</guid>
      <description>This tutorial describes the basic concepts of PVs, PVCs and storage classes and demonstrates how a cluster administrator can manage storage classes and persistent volumes in KubeSphere.
Introduction A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV.</description>
    </item>
    
    <item>
      <title>Release Notes For 2.1.1</title>
      <link>https://cnimages.github.io/website/docs/release/release-v211/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/release/release-v211/</guid>
      <description>KubeSphere 2.1.1 was released on Feb 23rd, 2020, which has fixed known bugs and brought some enhancements. For the users who have installed versions of 2.0.x or 2.1.0, make sure to read the user manual carefully about how to upgrade before doing that, and feel free to raise any questions on GitHub.
What&amp;rsquo;s New in 2.1.1 Installer UPGRADE &amp;amp; ENHANCEMENT  Support Kubernetes v1.14.x、v1.15.x、v1.16.x、v1.17.x，also solve the issue of Kubernetes API Compatibility#1829 Simplify the steps of installation on existing Kubernetes, and remove the step of specifying cluster&amp;rsquo;s CA certification, also specifying Etcd certification is no longer mandatory step if users don&amp;rsquo;t need Etcd monitoring metrics Backup the configuration of CoreDNS before upgrading  BUG FIXES  Fix the issue of importing apps to App Store  App Store UPGRADE &amp;amp; ENHANCEMENT  Upgrade OpenPitrix to v0.</description>
    </item>
    
    <item>
      <title>DevOps Project Management</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/devops-project-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/devops-project-management/</guid>
      <description>Prerequisites  You need to create a workspace, a project and an account (project-admin). Please refer to Create Workspace, Project, Account and Role if they are not ready yet. You need to enable KubeSphere DevOps system.  Create a DevOps  Sign in with project-admin, choose DevOps Projects tap, then click Create and select Create a DevOps project.  Fill in the basic information for this DevOps project.   Name: A concise and clear name for this DevOps project, which is convenient for users to browse and search, e.</description>
    </item>
    
    <item>
      <title>Build and Deploy a Go Project</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/examples/go-project-pipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/examples/go-project-pipeline/</guid>
      <description>Prerequisites  You need to enable KubeSphere DevOps System. You need to have a Docker Hub account. You need to create a workspace, a DevOps project, a project, and an account (project-regular). This account needs to be invited to the DevOps project and the project with the role operator. For more information, see Create Workspace, Project, Account and Role.  Create Docker Hub Access Token   Sign in Docker Hub and select Account Settings from the menu in the top right corner.</description>
    </item>
    
    <item>
      <title>How to build and deploy a maven project</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/examples/a-maven-project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/examples/a-maven-project/</guid>
      <description>Prerequisites  You need to enable KubeSphere DevOps System. You need to create DockerHub account. You need to create a workspace, a DevOps project, and a user account, and this account needs to be invited into the DevOps project as the role of maintainer.  Workflow for Maven Project As is shown in the graph, there is the workflow for a maven project in KubeSphere DevOps.
It uses the pipeline of Jenkins to build and deploy the maven project in KubeSphere DevOps.</description>
    </item>
    
    <item>
      <title>Cluster Visibility and Authorization</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/cluster-visibility-and-authorization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/cluster-visibility-and-authorization/</guid>
      <description>Objective This guide demonstrates how to set up cluster visibility. You can limit which clusters workspace can use with cluster visibility settings.
Prerequisites  You need to enable Multi-cluster Management. You need to create at least one workspace.  Set cluster visibility In KubeSphere, clusters can be authorized to multiple workspaces, and workspaces can also be associated with multiple clusters.
Set up available clusters when creating workspace  Log in to an account that has permission to create a workspace, such as ws-manager.</description>
    </item>
    
    <item>
      <title>Configure Authentication</title>
      <link>https://cnimages.github.io/website/docs/access-control-and-account-management/configuring-authentication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/access-control-and-account-management/configuring-authentication/</guid>
      <description>Objective This guide demonstrates how to set up authentication. You can use external identity providers such as LDAP or Active Directory for KubeSphere.
Prerequisites KubeSphere needs to be installed in your machines.
Overview KubeSphere includes a built-in OAuth server. Users obtain OAuth access tokens to authenticate themselves to the API.
As an administrator, you can configure OAuth by editing configmap to specify an identity provider.
Identity Providers KubeSphere has an internal account management system.</description>
    </item>
    
    <item>
      <title>Create a Pipeline Using a Jenkinsfile</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/create-a-pipeline-using-jenkinsfile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/create-a-pipeline-using-jenkinsfile/</guid>
      <description>A Jenkinsfile is a text file that contains the definition of a Jenkins pipeline and is checked into source control. As it stores the entire workflow as code, it underpins the code review and iteration process of a pipeline. For more information, see the official documentation of Jenkins.
This tutorial demonstrates how to create a pipeline based on a Jenkinsfile from a GitHub repository. Using the pipeline, you deploy an example application to a development environment and a production environment respectively, which is accessible externally.</description>
    </item>
    
    <item>
      <title>Integrate SonarQube into Pipeline</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/how-to-integrate/sonarqube/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/how-to-integrate/sonarqube/</guid>
      <description>SonarQube is a popular continuous inspection tool for code quality. You can use it for static and dynamic analysis of a codebase. After it is integrated into pipelines in KubeSphere, you can view common code issues such as bugs and vulnerabilities directly on the dashboard as SonarQube detects issues in a running pipeline.
This tutorial demonstrates how you can integrate SonarQube into pipelines. Refer to the following steps first before you create a pipeline using a Jenkinsfile.</description>
    </item>
    
    <item>
      <title>Node Management</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/nodes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/nodes/</guid>
      <description>Kubernetes runs your workloads by placing containers into Pods to run on nodes. A node may be a virtual or physical machine, depending on the cluster. Each node contains the services necessary to run Pods, managed by the control plane. For more information about nodes, see the official documentation of Kubernetes.
This tutorial demonstrates what a cluster administrator can view and do for nodes within a cluster.
Prerequisites You need an account granted a role including the authorization of Clusters Management.</description>
    </item>
    
    <item>
      <title>Release Notes For 2.1.0</title>
      <link>https://cnimages.github.io/website/docs/release/release-v210/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/release/release-v210/</guid>
      <description>KubeSphere 2.1.0 was released on Nov 11th, 2019, which fixes known bugs, adds some new features and brings some enhancement. If you have installed versions of 2.0.x, please upgrade it and enjoy the better user experience of v2.1.0.
Installer Enhancement  Decouple some components and make components including DevOps, service mesh, app store, logging, alerting and notification optional and pluggable Add Grafana (v5.2.4) as the optional component Upgrade Kubernetes to 1.</description>
    </item>
    
    <item>
      <title>Role and Member Management</title>
      <link>https://cnimages.github.io/website/docs/workspace-administration/role-and-member-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/workspace-administration/role-and-member-management/</guid>
      <description>This guide demonstrates how to manage roles and members in your workspace. For more information about KubeSphere roles, see Overview of Role Management.
In workspace scope, you can grant the following resources&amp;rsquo; permissions to a role:
 Projects DevOps Access Control Apps Management Workspace Settings  Prerequisites At least one workspace has been created, such as demo-workspace. Besides, you need an account of the workspace-admin role (e.g. ws-admin) at the workspace level.</description>
    </item>
    
    <item>
      <title>Upload Apps to KubeSphere Public Repository</title>
      <link>https://cnimages.github.io/website/docs/workspace-administration/app-repository/upload-app-to-public-repository/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/workspace-administration/app-repository/upload-app-to-public-repository/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>Glossary</title>
      <link>https://cnimages.github.io/website/docs/reference/glossary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/reference/glossary/</guid>
      <description>This glossary includes technical terms that are specific to KubeSphere, as well as more general terms that provide useful context.
General   Workspace A logical unit to organize a tenant&amp;rsquo;s workload projects / Kubernetes namespaces, DevOps projects, manage resource access and share information within the team.
  System Workspace The special place to organize system projects from KubeSphere, Kubernetes and optional components such as OpenPitrix, Istio, monitorng etc.</description>
    </item>
    
    <item>
      <title>KubeSphere API</title>
      <link>https://cnimages.github.io/website/docs/reference/api-docs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/reference/api-docs/</guid>
      <description>In KubeSphere v3.0, we move the functionalities of ks-apigateway, ks-account into ks-apiserver to make the architecture more compact and straight forward. In order to use KubeSphere API, you need to expose ks-apiserver to your client.
Step 1: Expose KubeSphere API service If you are going to access KubeSphere inside the cluster, you can skip the following section and just use the KubeSphere API server endpoint http://ks-apiserver.kubesphere-system.svc.
On the other hand, you need to expose the KubeSphere API server endpoint to the outside of the cluster first.</description>
    </item>
    
    <item>
      <title>Logging</title>
      <link>https://cnimages.github.io/website/docs/reference/api-changes/logging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/reference/api-changes/logging/</guid>
      <description>The API changes of logging component in KubeSphere v3.0.0.
Time format The time format for query parameters must be in Unix timestamp, which is the number of seconds that has elapsed since the Unix epoch. Millisecond is no longer allowed. The change affects the parameters start_time and end_time.
Deprecated APIs The following APIs are removed:
 GET /workspaces/{workspace} GET /namespaces/{namespace} GET /namespaces/{namespace}/workloads/{workload} GET /namespaces/{namespace}/pods/{pod} The whole log setting API group  Fluent Bit Operator In KubeSphere 3.</description>
    </item>
    
    <item>
      <title>Deploy RabbitMQ on KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/application-store/built-in-apps/rabbitmq-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/built-in-apps/rabbitmq-app/</guid>
      <description>RabbitMQ is the most widely deployed open-source message broker. It is lightweight and easy to deploy on premises and in the cloud. It supports multiple messaging protocols. RabbitMQ can be deployed in distributed and federated configurations to meet high-scale, high-availability requirements.
This tutorial walks you through an example of how to deploy RabbitMQ from the App Store of KubeSphere.
Prerequisites  Please make sure you enable the OpenPitrix system. You need to create a workspace, a project, and a user account for this tutorial.</description>
    </item>
    
    <item>
      <title>Monitoring</title>
      <link>https://cnimages.github.io/website/docs/reference/api-changes/monitoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/reference/api-changes/monitoring/</guid>
      <description>API Version The monitoring API version is bumped to v1alpha3.
Time format The time format for query parameters must be in Unix timestamp, which is the number of seconds that has elapsed since the Unix epoch. Decimal is no longer allowed. The change affects the parameters start, end and time.
Deprecated Metrics In KubeSphere 3.0.0, the metrics on the left have been renamed into the ones on the right.
   V2.</description>
    </item>
    
    <item>
      <title>Deploy MongoDB on KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/application-store/built-in-apps/mongodb-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/built-in-apps/mongodb-app/</guid>
      <description>MongoDB is a general purpose, document-based, distributed database built for modern application developers and for the cloud era.
This tutorial walks you through an example of deploying MongoDB from the App Store of KubeSphere.
Prerequisites  Please make sure you enable the OpenPitrix system. You need to create a workspace, a project, and a user account (project-regular) for this tutorial. The account needs to be a platform regular user and to be invited as the project operator with the operator role.</description>
    </item>
    
    <item>
      <title>Deploy NGINX on KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/application-store/built-in-apps/nginx-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/built-in-apps/nginx-app/</guid>
      <description>NGINX is an open-source software application for web serving, reverse proxying, caching, load balancing, media streaming, and more.
This tutorial walks you through an example of deploying NGINX from the App Store of KubeSphere.
Prerequisites  Please make sure you enable the OpenPitrix system. You need to create a workspace, a project, and a user account (project-regular) for this tutorial. The account needs to be a platform regular user and to be invited as the project operator with the operator role.</description>
    </item>
    
    <item>
      <title>Deploy Redis on KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/application-store/built-in-apps/redis-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/built-in-apps/redis-app/</guid>
      <description>Redis is an open-source (BSD licensed), in-memory data structure store, used as a database, cache and message broker.
This tutorial walks you through an example of deploying Redis from the App Store of KubeSphere.
Prerequisites  Please make sure you enable the OpenPitrix system. You need to create a workspace, a project, and a user account (project-regular) for this tutorial. The account needs to be a platform regular user and to be invited as the project operator with the operator role.</description>
    </item>
    
    <item>
      <title>Deploy Tomcat on KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/application-store/built-in-apps/tomcat-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/built-in-apps/tomcat-app/</guid>
      <description>Apache Tomcat powers numerous large-scale, mission-critical web applications across a diverse range of industries and organizations. Tomcat provides a pure Java HTTP web server environment in which Java code can run.
This tutorial walks you through an example of deploying Tomcat from the App Store of KubeSphere.
Prerequisites  Please make sure you enable the OpenPitrix system. You need to create a workspace, a project, and a user account for this tutorial.</description>
    </item>
    
    <item>
      <title>Cluster Status Monitoring</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/cluster-status-monitoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/cluster-status-monitoring/</guid>
      <description>KubeSphere provides monitoring of related metrics such as CPU, memory, network, and disk of the cluster. You can also review historical monitoring data and sort nodes by different indicators based on their usage in Cluster Status Monitoring.
Prerequisites You need an account granted a role including the authorization of Clusters Management. For example, you can log in the console as admin directly or create a new role with the authorization and assign it to an account.</description>
    </item>
    
    <item>
      <title>Create a Pipeline - using Graphical Editing Panel</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/create-a-pipeline-using-graphical-editing-panel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/create-a-pipeline-using-graphical-editing-panel/</guid>
      <description>We are going to show how to create a CI/CD pipeline without Jenkinsfile by visually editing the workflow through KubeSphere console.
Objective We will use the graphical editing panel in KubeSphere console to create a pipeline, which automates the processes and release the sample project to Kubernetes development environment. If you have tried the Jenkinsfile-based pipeline, the build steps for this tutorial are easy to understand. The sample project in this tutorial is same to this demo.</description>
    </item>
    
    <item>
      <title>Deploy Apps in a Multi-cluster Project Using Jenkinsfile</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/examples/multi-cluster-project-example/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/examples/multi-cluster-project-example/</guid>
      <description>Prerequisites  You need to enable the multi-cluster feature. You need to have a Docker Hub account. You need to enable KubeSphere DevOps System on your host cluster. You need to create a workspace with multiple clusters, a DevOps project on your host cluster, a multi-cluster project (in this tutorial, this multi-cluster project is created on the host cluster and one member cluster), and an account (project-regular). This account needs to be invited to the DevOps project and the multi-cluster project with the role operator.</description>
    </item>
    
    <item>
      <title>Release Notes For 2.0.2</title>
      <link>https://cnimages.github.io/website/docs/release/release-v202/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/release/release-v202/</guid>
      <description>KubeSphere 2.0.2 was released on July 9, 2019, which fixes known bugs and enhances existing feature. If you have installed versions of 1.0.x, 2.0.0 or 2.0.1, please download KubeSphere installer v2.0.2 to upgrade.
What&amp;rsquo;s New in 2.0.2 Enhanced Features  API docs are available on the official website. Block brute-force attacks. Standardize the maximum length of resource names. Upgrade the gateway of project (Ingress Controller) to the version of 0.24.1. Support Ingress grayscale release.</description>
    </item>
    
    <item>
      <title>Deploy MySQL on KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/application-store/built-in-apps/mysql-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/built-in-apps/mysql-app/</guid>
      <description>MySQL is an open-source relational database management system (RDBMS), which uses the most commonly used database management language - Structured Query Language (SQL) for database management. It provides a fully managed database service to deploy cloud-native applications using the world’s most popular open-source database.
This tutorial walks you through an example of deploying MySQL from the App Store of KubeSphere.
Prerequisites  Please make sure you enable the OpenPitrix system. You need to create a workspace, a project, and a user account for this tutorial.</description>
    </item>
    
    <item>
      <title>How to integrate Harbor in Pipeline</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/how-to-integrate/harbor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/how-to-integrate/harbor/</guid>
      <description>Prerequisites  You need to enable KubeSphere DevOps System. You need to create a workspace, a DevOps project, and a project-regular user account, and this account needs to be invited into a DevOps project. See create-workspace-and-project. You need to have installed Harbor already.  Install Harbor It is highly recommended that you install harbor by application store. You can also install harbor manally by helm3.
helm repo add harbor https://helm.goharbor.io # for qucik taste, you can expose harbor by nodeport and disable tls.</description>
    </item>
    
    <item>
      <title>Application Resources Monitoring</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/application-resources-monitoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/application-resources-monitoring/</guid>
      <description>In addition to monitoring data at the physical resource level, cluster administrators also need to keep a close track of application resources across the platform, such as the number of projects and DevOps projects, as well as the number of workloads and services of a specific type. Application resource monitoring provides a summary of resource usage and application-level trends of the platform.
Prerequisites You need an account granted a role including the authorization of Clusters Management.</description>
    </item>
    
    <item>
      <title>Choose Jenkins Agent</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/choose-jenkins-agent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/choose-jenkins-agent/</guid>
      <description>The agent section specifies where the entire Pipeline, or a specific stage, will execute in the Jenkins environment depending on where the agent section is placed. The section must be defined at the top-level inside the pipeline block, but stage-level usage is optional. For more information, see the official documentation of Jenkins.
Built-in podTemplate A podTemplate is a template of a Pod that is used to create agents. Users can define a podTemplate to use in the Kubernetes plugin.</description>
    </item>
    
    <item>
      <title>Credential Management</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/credential-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/credential-management/</guid>
      <description>Credentials are objects containing sensitive information, such as usernames and passwords, SSH keys, and tokens. When a KubeSphere DevOps pipeline is running, it interacts with objects in external environments to perform a series of tasks, including pulling code, pushing and pulling images, and running scripts. During this process, credentials need to be provided accordingly while they do not appear explicitly in the pipeline.
A DevOps project user with necessary permissions can configure credentials for Jenkins pipelines.</description>
    </item>
    
    <item>
      <title>Release Notes For 2.0.1</title>
      <link>https://cnimages.github.io/website/docs/release/release-v201/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/release/release-v201/</guid>
      <description>KubeSphere 2.0.1 was released on June 9th, 2019.
Bug Fix  Fix the issue that CI/CD pipeline cannot recognize correct special characters in the code branch. Fix CI/CD pipeline&amp;rsquo;s issue of being unable to check logs. Fix no-log data output problem caused by index document fragmentation abnormity during the log query. Fix prompt exceptions when searching for logs that do not exist. Fix the line-overlap problem on traffic governance topology and fixed invalid image strategy application.</description>
    </item>
    
    <item>
      <title>Set CI Node for Dependency Cache</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/set-ci-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/set-ci-node/</guid>
      <description>Generally, different dependencies need to be pulled as applications are being built. This may cause some issues such as long pulling time and network instability, further resulting in build failures. To provide your pipeline with a more enabling and stable environment, you can configure a node or a group of nodes specifically for continuous integration (CI). These CI nodes can speed up the building process by using caches.
This tutorial demonstrates how you set CI nodes so that KubeSphere schedules tasks of pipelines and S2I/B2I builds to these nodes.</description>
    </item>
    
    <item>
      <title>Set Email Server for KubeSphere Pipelines</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/jenkins-email/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/jenkins-email/</guid>
      <description>The built-in Jenkins cannot share the same email configuration with the platform notification system. Thus, you need to configure email server settings for KubeSphere DevOps pipelines separately.
Prerequisites  You need to enable KubeSphere DevOps System. You need an account granted a role including the authorization of Clusters Management. For example, you can log in the console as admin directly or create a new role with the authorization and assign it to an account.</description>
    </item>
    
    <item>
      <title>Release Notes For 2.0.0</title>
      <link>https://cnimages.github.io/website/docs/release/release-v200/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/release/release-v200/</guid>
      <description>KubeSphere 2.0.0 was released on May 18th, 2019.
What&amp;rsquo;s New in 2.0.0 Component Upgrades  Support Kubernetes Kubernetes 1.13.5 Integrate QingCloud Cloud Controller. After installing load balancer, QingCloud load balancer can be created through KubeSphere console and the backend workload is bound automatically.  Integrate QingStor CSI v0.3.0 storage plugin and support physical NeonSAN storage system. Support SAN storage service with high availability and high performance. Integrate QingCloud CSI v0.2.1 storage plugin and support many types of volume to create QingCloud block services.</description>
    </item>
    
    <item>
      <title>Role and Member Management</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/role-and-member-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/role-and-member-management/</guid>
      <description>This guide demonstrates how to manage roles and members in your DevOps project. For more information about KubeSphere roles, see Overview of Role Management.
In DevOps project scope, you can grant the following resources&amp;rsquo; permissions to a role:
 Pipelines Credentials DevOps Settings Access Control  Prerequisites At least one DevOps project has been created, such as demo-devops. Besides, you need an account of the admin role (e.g. devops-admin) at the DevOps project level.</description>
    </item>
    
    <item>
      <title>What is KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/introduction/what-is-kubesphere/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/introduction/what-is-kubesphere/</guid>
      <description>Overview KubeSphere is a distributed operating system managing cloud-native applications with Kubernetes as its kernel, providing a plug-and-play architecture for the seamless integration of third-party applications to boost its ecosystem.
KubeSphere also represents a multi-tenant enterprise-grade container platform with full-stack automated IT operation and streamlined DevOps workflows. It provides developer-friendly wizard web UI, helping enterprises to build out a more robust and feature-rich platform. It boasts the most common functionalities needed for enterprise Kubernetes strategies, such as Kubernetes resource management, DevOps (CI/CD), application lifecycle management, monitoring, logging, service mesh, multi-tenancy, alerting and notification, auditing, storage and networking, autoscaling, access control, GPU support, multi-cluster deployment and management, network policy, registry management, and security management.</description>
    </item>
    
    <item>
      <title>Features</title>
      <link>https://cnimages.github.io/website/docs/introduction/features/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/introduction/features/</guid>
      <description>Overview As an open source container platform, KubeSphere provides enterprises with a robust, secure and feature-rich platform, boasting the most common functionalities needed for enterprises adopting Kubernetes, such as multi-cluster deployment and management, network policy configuration, Service Mesh (Istio-based), DevOps projects (CI/CD), security management, Source-to-Image and Binary-to-Image, multi-tenant management, multi-dimensional monitoring, log query and collection, alerting and notification, auditing, application management, and image registry management.
It also supports various open source storage and network solutions, as well as cloud storage services.</description>
    </item>
    
    <item>
      <title>Architecture</title>
      <link>https://cnimages.github.io/website/docs/introduction/architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/introduction/architecture/</guid>
      <description>Separation of frontend and backend KubeSphere separates frontend from backend, and it itself is a cloud native application and provides open standard REST APIs for external systems to use. Please see API documentation for details. The following figure is the system architecture. KubeSphere can run anywhere from on-premise datacenter to any cloud to edge. In addition, it can be deployed on any Kubernetes distribution.
Components List    Back-end component Function description     ks-apiserver The KubeSphere API server validates and configures data for the API objects which include Kubernetes objects.</description>
    </item>
    
    <item>
      <title>Advantages</title>
      <link>https://cnimages.github.io/website/docs/introduction/advantages/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/introduction/advantages/</guid>
      <description>Vision Kubernetes has become the de facto standard for deploying containerized applications at scale in private, public and hybrid cloud environments. However, many people can easily get confused when they start to use Kubernetes as it is complicated and has many additional components to manage. Some components need to be installed and deployed by users themselves, such as storage and network services. At present, Kubernetes only provides open-source solutions or projects, which can be difficult to install, maintain and operate to some extent.</description>
    </item>
    
    <item>
      <title>Use Cases</title>
      <link>https://cnimages.github.io/website/docs/introduction/scenarios/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/introduction/scenarios/</guid>
      <description>KubeSphere is applicable in a variety of scenarios. For enterprises that deploy their business system on bare metal, their business modules are tightly coupled with each other. That means it is extremely difficult for resources to be horizontally scaled. In this connection, KubeSphere provides enterprises with containerized environments with a complete set of features for management and operation. It empowers enterprises to rise to the challenges in the middle of their digital transformation, including agile software development, automated operation and maintenance, microservices governance, traffic management, autoscaling, high availability, as well as DevOps and CI/CD.</description>
    </item>
    
    <item>
      <title>Glossary</title>
      <link>https://cnimages.github.io/website/docs/introduction/glossary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/introduction/glossary/</guid>
      <description>This document describes some frequently used glossaries in KubeSphere as shown below:
   Object Concepts     Project It is Kubernetes Namespace which provides virtual isolation for the resources in KubeSphere, see Namespace.   Pod A Pod is the smallest deployable computing unit that can be created and managed in KubeSphere, see Pods.   Deployment Deployment is used to describe a desired state in a deployment object, and the deployment controller changes the actual state to the desired state at a controlled rate, see Deployment.</description>
    </item>
    
    <item>
      <title>Manage alerts with Alertmanager in KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/cluster-wide-alerting-and-notification/alertmanager/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/cluster-wide-alerting-and-notification/alertmanager/</guid>
      <description>Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct receiver integration such as email, PagerDuty, or OpsGenie. It also takes care of silencing and inhibition of alerts. For more details, please refer to Alertmanager guide.
KubeSphere has been using Prometheus as its monitoring service&amp;rsquo;s backend from the first release. Starting from v3.0, KubeSphere adds Alertmanager to its monitoring stack to manage alerts sent from Prometheus as well as other components such as kube-events and kube-auditing.</description>
    </item>
    
    <item>
      <title>Manage multi-tenant notifications with Notification Manager</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/cluster-wide-alerting-and-notification/notification-manager/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/cluster-wide-alerting-and-notification/notification-manager/</guid>
      <description>Notification Manager manages notifications in KubeSphere. It receives alerts or notifications from different senders and then sends notifications to different users.
Supported senders includes:
 Prometheus Alertmanager Custom sender (Coming soon)  Supported receivers includes:
 Email Wechat Work Slack Webhook (Coming soon)  QuickStart Config Prometheus Alertmanager to send alerts to Notification Manager Notification Manager uses port 19093 and API path /api/v2/alerts to receive alerts sent from Prometheus Alertmanager of Kubesphere.</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/log-collections/introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/log-collections/introduction/</guid>
      <description>KubeSphere provides a flexible log collection configuration method. Powered by FluentBit Operator, users can add/modify/delete/enable/disable Elasticsearch, Kafka and Fluentd receivers with ease. Once a receiver is added, logs will be sent to this receiver.
Prerequisite Before adding a log receiver, you need to enable any of the logging, events or auditing components following Enable Pluggable Components.
Add Log Receiver (aka Collector) for container logs To add a log receiver:
 Login with an account of platform-admin role Click Platform -&amp;gt; Clusters Management Select a cluster if multiple clusters exist Click Cluster Settings -&amp;gt; Log Collections Log receivers can be added by clicking Add Log Collector  Note</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/introduction/</guid>
      <description>Custom monitoring allows you to monitor and visualize custom application metrics in KubeSphere. The application can be either a third-party application, such as MySQL, Redis, and Elasticsearch, or your own applications. This section introduces the workflow of this feature.
The KubeSphere monitoring engine is powered by Prometheus and Prometheus Operator. To integrate custom application metrics into KubeSphere, you need to go through the following steps in general.
 Expose Prometheus-Formatted Metrics of your application.</description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://cnimages.github.io/website/docs/installing-on-kubernetes/introduction/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-kubernetes/introduction/overview/</guid>
      <description>As part of KubeSphere&amp;rsquo;s commitment to provide a plug-and-play architecture for users, it can be easily installed on existing Kubernetes clusters. More specifically, KubeSphere can be deployed on Kubernetes either hosted on clouds (e.g. AWS EKS, QingCloud QKE and Google GKE) or on-premises. This is because KubeSphere does not hack Kubernetes itself. It only interacts with the Kubernetes API to manage Kubernetes cluster resources. In other words, KubeSphere can be installed on any native Kubernetes cluster and Kubernetes distribution.</description>
    </item>
    
    <item>
      <title>ConfigMaps</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/configuration/configmaps/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/configuration/configmaps/</guid>
      <description>A Kubernets ConfigMap is used to store configuration data in the form of key-value pairs. The ConfigMap resource provides a way to inject configuration data into Pods. The data stored in a ConfigMap object can be referenced in a volume of type ConfigMap and then consumed by containerized applications running in a Pod. ConfigMaps are often used in the following cases:
 Set the value of the environment variable. Set command parameters in the container.</description>
    </item>
    
    <item>
      <title>Monitor MySQL</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/examples/monitor-mysql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/examples/monitor-mysql/</guid>
      <description>From the Introduction section, you know it is not feasible to instrument MySQL with Prometheus metrics directly. To expose MySQL metrics in Prometheus format, you need to deploy MySQL exporter instead.
This tutorial walks you through an example of how to monitor MySQL metrics and visualize them.
Prerequisites  Please make sure you enable the OpenPitrix system. MySQL and MySQL exporter will be deployed from the App Store. You need to create a workspace, a project, and a user account for this tutorial.</description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/introduction/intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/introduction/intro/</guid>
      <description>For the installation on Linux, KubeSphere can be installed both in clouds and in on-premises environments, such as AWS EC2, Azure VM and bare metal. Users can install KubeSphere on Linux hosts as they provision fresh Kubernetes clusters. The installation process is easy and friendly. Meanwhile, KubeSphere offers not only the online installer, or KubeKey, but also an air-gapped installation solution for the environment with no Internet access.
As an open-source project on GitHub, KubeSphere is home to a community with thousands of users.</description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/grayscale-release/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/grayscale-release/overview/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>Project Quotas</title>
      <link>https://cnimages.github.io/website/docs/project-administration/project-quota/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-administration/project-quota/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>Volumes</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/storage/volumes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/storage/volumes/</guid>
      <description>Introduction In this section, volumes always refer to PersistentVolumeClaim(PVC) of Kubernetes.
Create Volume Method There are two methods to create volume:
 Create empty volume by StorageClass Create volume from VolumeSnapshot  Attach Volume onto Workloads Take attaching volume onto deployment for example, in the Mount Volume step of Create Deployment, volumes cloud be attached on containers&amp;rsquo; path. Volume Features Volume Features include:
 Clone Volume Create Volume Snapshot Expand Volume  KubeSphere can get supported features of underlying storage plugin called Storage Capability.</description>
    </item>
    
    <item>
      <title>Multi-node Installation</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/introduction/multioverview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/introduction/multioverview/</guid>
      <description>In a production environment, a single-node cluster cannot satisfy most of the needs as the cluster has limited resources with insufficient compute capabilities. Thus, single-node clusters are not recommended for large-scale data processing. Besides, a cluster of this kind is not available with high availability as it only has one node. On the other hand, a multi-node architecture is the most common and preferred choice in terms of application deployment and distribution.</description>
    </item>
    
    <item>
      <title>Air-gapped Installation</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/introduction/air-gapped-installation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/introduction/air-gapped-installation/</guid>
      <description>The air-gapped installation is almost the same as the online installation except that you must create a local registry to host Docker images. This tutorial demonstrates how to install KubeSphere and Kubernetes in an air-gapped environment.
Step 1: Prepare Linux Hosts Please see the requirements for hardware and operating system shown below. To get started with multi-node installation, you need to prepare at least three hosts according to the following requirements.</description>
    </item>
    
    <item>
      <title>Monitor Sample Web</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/examples/monitor-sample-web/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/examples/monitor-sample-web/</guid>
      <description>This section walks you through monitoring a sample web application. The application is instrumented with Prometheus Go client in its code. Therefore, it can expose metrics directly without the help of exporters.
Prerequisites   Please make sure you enable the OpenPitrix system.
  You need to create a workspace, a project, and a user account for this tutorial. For more information, see Create Workspace, Project, Account and Role. The account needs to be a platform regular user and to be invited as the workspace self provisioner with the self-provisioner role.</description>
    </item>
    
    <item>
      <title>Port Requirements</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/introduction/port-firewall/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/introduction/port-firewall/</guid>
      <description>KubeSphere requires certain ports for the communications among services. If your network is configured with firewall rules, you need to ensure infrastructure components can communicate with each other through specific ports that act as communication endpoints for certain processes or services.
   Service Protocol Action Start Port End Port Notes     ssh TCP allow 22     etcd TCP allow 2379 2380    apiserver TCP allow 6443     calico TCP allow 9099 9100    bgp TCP allow 179     nodeport TCP allow 30000 32767    master TCP allow 10250 10258    dns TCP allow 53     dns UDP allow 53     local-registry TCP allow 5000  For offline environment   local-apt TCP allow 5080  For offline environment   rpcbind TCP allow 111  Required if NFS is used   ipip IPENCAP / IPIP allow   Calico needs to allow the ipip protocol    Note</description>
    </item>
    
    <item>
      <title>Secrets</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/configuration/secrets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/configuration/secrets/</guid>
      <description>A Kubernets Secret is used to store and manage sensitive information, such as passwords, OAuth tokens, and ssh keys. To use a Secret, a Pod needs to reference it in one of the following ways.
 As a file in a volume mounted and consumed by containerized applications running in a Pod. As environment variable used by containers in a Pod. As image registry crendential when pulling images for the Pod by the kubelet.</description>
    </item>
    
    <item>
      <title>Prerequisites</title>
      <link>https://cnimages.github.io/website/docs/installing-on-kubernetes/introduction/prerequisites/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-kubernetes/introduction/prerequisites/</guid>
      <description>Not only can KubeSphere be installed on virtual machines and bare metal with provisioned Kubernetes, but also supports installing on cloud-hosted and on-premises existing Kubernetes clusters as long as your Kubernetes cluster meets the prerequisites below.
 Kubernetes version: 1.15.x, 1.16.x, 1.17.x, 1.18.x; CPU &amp;gt; 1 Core; Memory &amp;gt; 2 G; A default Storage Class in your Kubernetes cluster is configured; use kubectl get sc to verify it. The CSR signing feature is activated in kube-apiserver when it is started with the --cluster-signing-cert-file and --cluster-signing-key-file parameters.</description>
    </item>
    
    <item>
      <title>Blue-green Deployment</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/grayscale-release/blue-green-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/grayscale-release/blue-green-deployment/</guid>
      <description>The blue-green release provides a zero downtime deployment, which means the new version can be deployed with the old one preserved. At any time, only one of the versions is active serving all the traffic, while the other one remains idle. If there is a problem with running, you can quickly roll back to the old version.
Prerequisites  You need to enable KubeSphere Service Mesh. You need to create a workspace, a project and an account (project-regular).</description>
    </item>
    
    <item>
      <title>Canary Release</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/grayscale-release/canary-release/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/grayscale-release/canary-release/</guid>
      <description>On the back of Istio, KubeSphere provides users with necessary control to deploy canary services. In a canary release, you introduce a new version of a service and test it by sending a small percentage of traffic to it. At the same time, the old version is responsible for handling the rest of the traffic. If everything goes well, you can gradually increase the traffic sent to the new version, while simultaneously phasing out the old version.</description>
    </item>
    
    <item>
      <title>Image Registry</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/configuration/image-registry/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/configuration/image-registry/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>Kubernetes Cluster Configuration</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/introduction/vars/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/introduction/vars/</guid>
      <description>This tutorial explains how to customize Kubernetes cluster configurations in config-sample.yaml (needed for Multi-node Installation) when you use KubeKey to provision a cluster. You can refer to the following section to understand each parameter.
######################### Kubernetes ######################### kubernetes: version: v1.17.9 # The default k8s version is v1.17.9; you can specify 1.15.2, v1.16.13 or v1.18.6 based on your needs. imageRepo: kubesphere # DockerHub Repo clusterName: cluster.local # Kubernetes Cluster Name masqueradeAll: false # masqueradeAll tells kube-proxy to SNAT everything if using the pure iptables proxy mode.</description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/visualization/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/visualization/overview/</guid>
      <description>This section introduces dashboard features. You will learn how to visualize metric data in KubeSphere for your custom applications. If you do not know how to integrate your application metrics into KubeSphere monitoring system, read Introduction first.
Create Dashboard To create new dashboards for your application metrics, navigate to Custom Monitoring on the project Overview page. There are three ways to create dashboards. For MySQL, Elasticsearch, and Redis, you can use built-in templates.</description>
    </item>
    
    <item>
      <title>Project Gateway</title>
      <link>https://cnimages.github.io/website/docs/project-administration/project-gateway/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-administration/project-gateway/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>Project Network Isolation</title>
      <link>https://cnimages.github.io/website/docs/project-administration/project-network-isolation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-administration/project-network-isolation/</guid>
      <description>KubeSphere project network isolation lets project administrators enforce which network traffic is allowed using rules.
Prerequisites  You have already enabled Network Policy. Please refer to network-policy if it is not ready yet. Use an account of the admin role at the project level. For example, use the account project-admin created in Create Workspace, Project, Account and Role.  Note
For the implementation of the Network Policy, you can refer to kubesphere-network-policy Enable/Disable Project Network Isolation By default project network isolation is disabled, you can turn on network isolation via Project Settings/Network Isolation Note</description>
    </item>
    
    <item>
      <title>Projects and Multi-cluster Projects</title>
      <link>https://cnimages.github.io/website/docs/project-administration/project-and-multicluster-project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-administration/project-and-multicluster-project/</guid>
      <description>A project in KubeSphere is a Kubernetes namespace, which is used to organize resources into non-overlapping groups. It represents a logical partitioning capability as it divides cluster resources between multiple tenants.
A multi-cluster project runs across clusters, empowering users to achieve high availability and isolate occurring issues to a certain cluster while not affecting your business. For more information, see Multi-cluster Management.
This chapter demonstrates the basic operations of project administration, such as creation and deletion.</description>
    </item>
    
    <item>
      <title>Role and Member Management</title>
      <link>https://cnimages.github.io/website/docs/project-administration/role-and-member-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-administration/role-and-member-management/</guid>
      <description>This guide demonstrates how to manage roles and members in your project. For more information about KubeSphere roles, see Overview of Role Management.
In project scope, you can grant the following resources&amp;rsquo; permissions to a role:
 Application Workloads Storage Configurations Monitoring &amp;amp; Alerting Project Settings Access Control  Prerequisites At least one project has been created, such as demo-project. Besides, you need an account of the admin role (e.g. project-admin) at the project level.</description>
    </item>
    
    <item>
      <title>Traffic Mirroring</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/grayscale-release/traffic-mirroring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/grayscale-release/traffic-mirroring/</guid>
      <description>Traffic mirroring, also called shadowing, is a powerful, risk-free method of testing your app versions as it sends a copy of live traffic to a service that is being mirrored. Namely, you implement a similar setup for acceptance test so that problems can be detected in advance. As mirrored traffic happens out of band of the critical request path for the primary service, your end users will not be affected during the whole process.</description>
    </item>
    
    <item>
      <title>Volume Snapshots</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/storage/volume-snapshots/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/storage/volume-snapshots/</guid>
      <description>Introduction Many storage systems provide the ability to create a &amp;ldquo;snapshot&amp;rdquo; of a persistent volume. A snapshot represents a point-in-time copy of a volume. A snapshot can be used either to provision a new volume (pre-populated with the snapshot data) or to restore the existing volume to a previous state (represented by the snapshot).
On KubeSphere, requirements for Volume Snapshot are:
 With 1.17+ Kubernetes Underlying storage plugin supports Snapshot  Create Volume Snapshot Volume Snapshot could be created from an existing volume on the volume detail page.</description>
    </item>
    
    <item>
      <title>Workspace Network Isolation</title>
      <link>https://cnimages.github.io/website/docs/workspace-administration/workspace-network-isolation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/workspace-administration/workspace-network-isolation/</guid>
      <description>Prerequisites  You have already enabled Network Policy. Please refer to network-policy it is not ready yet. Use an account of the workspace-admin role. For example, use the account ws-admin created in Create Workspace, Project, Account and Role. Note
For the implementation of the network policy, you can refer to kubesphere-network-policy  Enable/Disable Workspace Network Isolation Workspace network isolation is disabled by default. You can turn on network isolation in Basic Info under Workspace Settings.</description>
    </item>
    
    <item>
      <title>Panels</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/visualization/panel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/visualization/panel/</guid>
      <description>KubeSphere currently supports two kinds of charts: text charts and graph charts.
Text A text chart is preferable for displaying a single metric value. The editing window for the text chart is composed of two parts. The upper part displays the real-time metric value, and the lower part is for editing. You can input a PromQL expression to fetch a single metric value.
 Chart Name: the name of the text chart.</description>
    </item>
    
    <item>
      <title>Persistent Storage Configuration</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/introduction/storage-configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/introduction/storage-configuration/</guid>
      <description>Overview Persistent volumes are a Must for installing KubeSphere. KubeKey lets KubeSphere be installed on different storage systems by the add-on mechanism. General steps of installing KubeSphere by KubeKey on Linux are:
 Install Kubernetes. Install the add-on plugin for KubeSphere. Install Kubesphere by ks-installer.  In KubeKey configurations, spec.persistence.storageClass of ClusterConfiguration needs to be set for ks-installer to create a PersistentVolumeClaim (PVC) for KubeSphere. If it is empty, the default StorageClass (annotation storageclass.</description>
    </item>
    
    <item>
      <title>Querying</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/visualization/querying/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/custom-application-monitoring/visualization/querying/</guid>
      <description>In the query editor, you can input PromQL expressions to process and fetch metrics. To learn how to write PromQL, please read Querying Examples.</description>
    </item>
    
    <item>
      <title>Add Elasticsearch as receiver (aka Collector)</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/log-collections/add-es-as-receiver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/log-collections/add-es-as-receiver/</guid>
      <description>KubeSphere supports using Elasticsearch, Kafka and Fluentd as log receivers. This doc will demonstrate how to add an Elasticsearch receiver.
Prerequisite Before adding a log receiver, you need to enable any of the logging, events or auditing components following Enable Pluggable Components. The logging component is enabled as an example in this doc.
  To add a log receiver:
 Login KubeSphere with an account of platform-admin role Click Platform -&amp;gt; Clusters Management Select a cluster if multiple clusters exist Click Cluster Settings -&amp;gt; Log Collections Log receivers can be added by clicking Add Log Collector    Choose Elasticsearch and fill in the Elasticsearch service address and port like below:</description>
    </item>
    
    <item>
      <title>App Templates</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application/app-template/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application/app-template/</guid>
      <description>An app template serves as a way for users to upload, deliver and manage apps. Generally, an app is composed of one or more Kubernetes workloads (e.g. Deployments, StatefulSets and DaemonSets) and Services based on how it functions and communicates with the external environment. Apps that are uploaded as app templates are built based on a Helm package.
How App Templates Work You can deliver Helm charts to the public repository of KubeSphere or import a private app repository to offer app templates.</description>
    </item>
    
    <item>
      <title>Alerting Policy (Workload Level)</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/alerting/alerting-policy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/alerting/alerting-policy/</guid>
      <description>Objective KubeSphere provides alert policies for nodes and workloads. This guide demonstrates how you, as a project member, can create alert policies for workloads in the project and configure mail notifications. See Alerting Policy (Node Level) to learn how to configure alert policies for nodes.
Prerequisites  KubeSphere Alerting and Notification needs to be enabled by an account granted the role platform-admin. Mail Server needs to be configured by an account granted the role platform-admin.</description>
    </item>
    
    <item>
      <title>Deploy Application from App Template</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application/deploy-app-from-template/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application/deploy-app-from-template/</guid>
      <description>Objective This tutorial shows you how to quickly deploy a Grafana application using templates from private repository sponsored by OpenPitrix. The demonstration includes importing application repository, sharing and deploying apps within a workspace.
Prerequisites  You have enabled OpenPitirx. You have completed the tutorial in Create Workspace, Project, Account and Role.  Hands-on Lab Step 1: Add an Application Repository  Note: The application repository can be hosted by either object storage, e.</description>
    </item>
    
    <item>
      <title>Alerting Message (Workload Level)</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/alerting/alerting-message/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/alerting/alerting-message/</guid>
      <description>Alert messages record detailed information of alerts triggered based on alert rules, including monitoring targets, alert policies, recent notifications and comments.
Prerequisites You have created a workload-level alert policy and received alert notifications of it. If it is not ready, please refer to Alert Policy (Workload Level) to create one first.
Hands-on Lab Task 1: View Alert Message  Log in the console and go to your project. Navigate to Alerting Message under Monitoring &amp;amp; Alerting, and you can see alert messages in the list.</description>
    </item>
    
    <item>
      <title>Deploy Application from App Store</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application/deploy-app-from-appstore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application/deploy-app-from-appstore/</guid>
      <description>Objective This tutorial shows you a simple example about how to quickly deploy a Nginx application from KubeSphere App Store sponsored by OpenPitrix. The App Store is also the public application repository in the platform, which means anybody can view the applications in the store, and any authenticated users can deploy applications from the store. This is typically different than the private application repositories only accessible within tenant&amp;rsquo;s workspaces. The demonstration includes one-click deploying apps from the App Store and exposing service by NodePort.</description>
    </item>
    
    <item>
      <title>Deploy KubeSphere on Azure VM Instance</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/public-cloud/install-ks-on-azure-vms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/public-cloud/install-ks-on-azure-vms/</guid>
      <description>Before You Begin Technically, you can either install and manage Kubernetes yourself or adopt a managed Kubernetes solution. If you are looking for a hands-off approach to taking advantage of Kubernetes, a fully-managed platform solution may suit you best. Please see Deploy KubeSphere on AKS for more details. However, if you want a bit more control over your configuration and set up a highly-available cluster on Azure, this instruction will help you to create a production-ready Kubernetes and KubeSphere cluster.</description>
    </item>
    
    <item>
      <title>Deploy KubeSphere on QingCloud Instance</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/public-cloud/kubesphere-on-qingcloud-instance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/public-cloud/kubesphere-on-qingcloud-instance/</guid>
      <description>Introduction For a production environment, we need to consider the high availability of the cluster. If the key components (e.g. kube-apiserver, kube-scheduler, and kube-controller-manager) are all running on the same master node, Kubernetes and KubeSphere will be unavailable once the master node goes down. Therefore, we need to set up a high-availability cluster by provisioning load balancers with multiple master nodes. You can use any cloud load balancer, or any hardware load balancer (e.</description>
    </item>
    
    <item>
      <title>Compose a Microservice App</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application/compose-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application/compose-app/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>Deployments</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/deployments/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/deployments/</guid>
      <description>A Deployment controller provides declarative updates for Pods and ReplicaSets. You describe a desired state in a Deployment object, and the Deployment controller changes the actual state to the desired state at a controlled rate. As a Deployment runs a number of replicas of your application, it automatically replaces instances that go down or malfunction. This is how Deployments make sure app instances are available to handle user requests.
For more information, see the official documentation of Kubernetes.</description>
    </item>
    
    <item>
      <title>Air-Gapped Installation</title>
      <link>https://cnimages.github.io/website/docs/application-store/app-developer-guide/helm-developer-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/app-developer-guide/helm-developer-guide/</guid>
      <description>The air-gapped installation is almost the same as the online installation except it creates a local registry to host the Docker images. We will demonstrate how to install KubeSphere and Kubernetes on air-gapped environment.
 Note: The dependencies in different operating systems may cause upexpected problems. If you encounter any installation problems on air-gapped environment, please describe your OS information and error logs on GitHub.
 Prerequisites  If your machine is behind a firewall, you need to open the ports by following the document Ports Requirements for more information.</description>
    </item>
    
    <item>
      <title>Air-Gapped Installation</title>
      <link>https://cnimages.github.io/website/docs/application-store/app-developer-guide/helm-specification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/app-developer-guide/helm-specification/</guid>
      <description>The air-gapped installation is almost the same as the online installation except it creates a local registry to host the Docker images. We will demonstrate how to install KubeSphere and Kubernetes on air-gapped environment.
 Note: The dependencies in different operating systems may cause upexpected problems. If you encounter any installation problems on air-gapped environment, please describe your OS information and error logs on GitHub.
 Prerequisites  If your machine is behind a firewall, you need to open the ports by following the document Ports Requirements for more information.</description>
    </item>
    
    <item>
      <title>Air-gapped Installation</title>
      <link>https://cnimages.github.io/website/docs/installing-on-kubernetes/on-prem-kubernetes/install-ks-on-linux-airgapped/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-kubernetes/on-prem-kubernetes/install-ks-on-linux-airgapped/</guid>
      <description>The air-gapped installation is almost the same as the online installation except that you must create a local registry to host Docker images. This tutorial demonstrates how to install KubeSphere on Kubernetes in an air-gapped environment.
Before you follow the steps below, read Prerequisites first.
Step 1: Prepare a Private Image Registry You can use Harbor or any other private image registries. This tutorial uses Docker registry as an example with self-signed certificates (If you have your own private image registry, you can skip this step).</description>
    </item>
    
    <item>
      <title>Application Lifecycle Management</title>
      <link>https://cnimages.github.io/website/docs/application-store/app-lifecycle-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/app-lifecycle-management/</guid>
      <description>KubeSphere integrates OpenPitrix, an open-source multi-cloud application management platform, to set up the App Store, managing applications throughout their entire lifecycle. The App Store supports two kinds of application deployment:
 App template provides a way for developers and independent software vendors (ISVs) to share applications with users in a workspace. You can also import third-party app repositories within a workspace. Composing app means users can quickly build a complete application using multiple microservices to compose it.</description>
    </item>
    
    <item>
      <title>Deploy etcd on KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/application-store/built-in-apps/etcd-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/built-in-apps/etcd-app/</guid>
      <description>Written in Go, etcd is a distributed key-value store to store data that needs to be accessed by a distributed system or cluster of machines. In Kubernetes, it is the backend for service discovery and stores cluster states and configurations.
This tutorial walks you through an example of deploying etcd from the App Store of KubeSphere.
Prerequisites  Please make sure you enable the OpenPitrix system. You need to create a workspace, a project, and a user account (project-regular) for this tutorial.</description>
    </item>
    
    <item>
      <title>GitLab App</title>
      <link>https://cnimages.github.io/website/docs/application-store/external-apps/gitlab-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/external-apps/gitlab-app/</guid>
      <description>Objective This tutorial shows you how to quickly deploy a GitLab application using templates from KubeSphere Helm repo. The demonstration includes importing application repository, sharing and deploying apps within a workspace.
Prerequisites  You have enabled KubeSphere Application Store You have completed the tutorial Create Workspace, Project, Account and Role. The account needs to be a platform regular user and to be invited as the project operator with the operator role.</description>
    </item>
    
    <item>
      <title>StatefulSets</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/statefulsets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/statefulsets/</guid>
      <description>As workload API object, a StatefulSet is used to manage stateful applications. It is responsible for the deploying, scaling of a set of Pods, and guarantees the ordering and uniqueness of these Pods.
Like a Deployment, a StatefulSet manages Pods that are based on an identical container specification. Unlike a Deployment, a StatefulSet maintains a sticky identity for each of their Pods. These pods are created from the same specification, but are not interchangeable: each has a persistent identifier that it maintains across any rescheduling.</description>
    </item>
    
    <item>
      <title>Uninstalling KubeSphere from Kubernetes</title>
      <link>https://cnimages.github.io/website/docs/installing-on-kubernetes/uninstalling/uninstalling-kubesphere-from-k8s/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-kubernetes/uninstalling/uninstalling-kubesphere-from-k8s/</guid>
      <description>You can uninstall KubeSphere from your existing Kubernetes cluster as follows.
Tip
Uninstall will remove KubeSphere from your Kubernetes cluster. This operation is irreversible and does not have any backup. Please be cautious with this operation. You can use kubesphere-delete.sh to uninstall KubeSphere from Kubernetes. Copy it from GitHub source file and execute this script in your local.</description>
    </item>
    
    <item>
      <title>Deploy Memcached on KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/application-store/built-in-apps/memcached-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/built-in-apps/memcached-app/</guid>
      <description>Memcached is an in-memory key-value store for small chunks of arbitrary data (strings, objects) from results of database calls, API calls, or page rendering. Its API is available for the majority of popular languages.
This tutorial walks you through an example of deploying Memcached from the App Store of KubeSphere.
Prerequisites  Please make sure you enable the OpenPitrix system. You need to create a workspace, a project, and a user account (project-regular) for this tutorial.</description>
    </item>
    
    <item>
      <title>Deploy MinIO on KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/application-store/built-in-apps/minio-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/built-in-apps/minio-app/</guid>
      <description>MinIO object storage is designed for high performance and the S3 API. It is ideal for large, private cloud environments with stringent security requirements and delivers mission-critical availability across a diverse range of workloads.
This tutorial walks you through an example of deploying MinIO from the App Store of KubeSphere.
Prerequisites  Please make sure you enable the OpenPitrix system. You need to create a workspace, a project, and a user account (project-regular) for this tutorial.</description>
    </item>
    
    <item>
      <title>Deploy PostgreSQL on KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/application-store/built-in-apps/postgresql-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/built-in-apps/postgresql-app/</guid>
      <description>PostgreSQL is a powerful, open-source object-relational database system which is famous for reliability, feature robustness, and performance.
This tutorial walks you through an example of how to deploy PostgreSQL from the App Store of KubeSphere.
Prerequisites  Please make sure you enable the OpenPitrix system. You need to create a workspace, a project, and a user account (project-regular) for this tutorial. The account needs to be a platform regular user and to be invited as the project operator with the operator role.</description>
    </item>
    
    <item>
      <title>Harbor App</title>
      <link>https://cnimages.github.io/website/docs/application-store/built-in-apps/harbor-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/application-store/built-in-apps/harbor-app/</guid>
      <description>From the Introduction section, you know there was uncounted application could be installed by helm. kubesphere&amp;#39;s App Store also added some popular application.
This tutorial walks you through an example of how to deploy Harbor with several click in kubesphere.
Prerequisites  Please make sure you enable the OpenPitrix system. We will deploy Harbor from the App Store. You need to create a workspace, a project, and a user account for this tutorial.</description>
    </item>
    
    <item>
      <title>Deploy KubeSphere on AKS</title>
      <link>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-kubesphere-on-aks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-kubesphere-on-aks/</guid>
      <description>This guide walks you through the steps of deploying KubeSphere on Azure Kubernetes Service.
Prepare an AKS cluster Azure can help you implement infrastructure as code by providing resource deployment automation options. Commonly adopted tools include ARM templates and Azure CLI. In this guide, we will use Azure CLI to create all the resources that are needed for the installation of KubeSphere.
Use Azure Cloud Shell You don&amp;rsquo;t have to install Azure CLI on your machine as Azure provides a web-based terminal.</description>
    </item>
    
    <item>
      <title>DaemonSets</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/daemonsets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/daemonsets/</guid>
      <description>A DaemonSet manages groups of replicated Pods while it ensures that all (or some) nodes run a copy of a Pod. As nodes are added to the cluster, DaemonSets automatically add Pods to the new nodes as needed.
For more information, see the official documentation of Kubernetes.
Use DaemonSets DaemonSets are very helpful in cases where you want to deploy ongoing background tasks that run on all or certain nodes without any user intervention.</description>
    </item>
    
    <item>
      <title>Deploy KubeSphere on VMware vSphere</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/on-premises/install-kubesphere-on-vmware-vsphere/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/on-premises/install-kubesphere-on-vmware-vsphere/</guid>
      <description>Introduction For a production environment, we need to consider the high availability of the cluster. If the key components (e.g. kube-apiserver, kube-scheduler, and kube-controller-manager) are all running on the same master node, Kubernetes and KubeSphere will be unavailable once the master node goes down. Therefore, we need to set up a high-availability cluster by provisioning load balancers with multiple master nodes. You can use any cloud load balancer, or any hardware load balancer (e.</description>
    </item>
    
    <item>
      <title>Services</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/services/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/services/</guid>
      <description>A Service is an abstract way to expose an application running on a set of Pods as a network service. Namely, a Service groups endpoints of these Pods into a single resource, which can be accessed through different ways.
With Kubernetes, you don&amp;rsquo;t need to modify your application to use an unfamiliar service discovery mechanism. Kubernetes gives Pods their IP addresses and a single DNS name for a set of Pods, and can load-balance across them.</description>
    </item>
    
    <item>
      <title>Deploy KubeSphere on Bare Metal</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/on-premises/install-kubesphere-on-bare-metal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/on-premises/install-kubesphere-on-bare-metal/</guid>
      <description>Introduction In addition to the deployment on cloud, KubeSphere can also be installed on bare metal. As the virtualization layer is removed, the infrastructure overhead is drastically reduced, which brings more compute and storage resources to app deployments. As a result, hardware efficiency is improved. Refer to the example below of how to deploy KubeSphere on bare metal.
Prerequisites  Please make sure that you already know how to install KubeSphere with a multi-node cluster based on the tutorial Multi-node Installation.</description>
    </item>
    
    <item>
      <title>Deploy KubeSphere on AWS EKS</title>
      <link>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-kubesphere-on-eks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-kubesphere-on-eks/</guid>
      <description>This guide walks you through the steps of deploying KubeSphere on AWS EKS.
Install the AWS CLI First we need to install the AWS CLI. Below is an example for macOS and please refer to Getting Started EKS for other operating systems.
pip3 install awscli --upgrade --user Check the installation with aws --version. Prepare an EKS Cluster   A standard Kubernetes cluster in AWS is a prerequisite of installing KubeSphere.</description>
    </item>
    
    <item>
      <title>Deploy KubeSphere on DigitalOcean</title>
      <link>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-kubesphere-on-do/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-kubesphere-on-do/</guid>
      <description>This guide walks you through the steps of deploying KubeSphere on DigitalOcean Kubernetes.
Prepare a DOKS Cluster A Kubernetes cluster in DO is a prerequisite for installing KubeSphere. Go to your DO account and refer to the image below to create a cluster from the navigation menu.
You need to select:
 Kubernetes version (e.g. 1.18.6-do.0) Datacenter region (e.g. Frankfurt) VPC network (e.g. default-fra1) Cluster capacity (e.g. 2 standard nodes with 2 vCPUs and 4GB of RAM each) A name for the cluster (e.</description>
    </item>
    
    <item>
      <title>Deploy KubeSphere on GKE</title>
      <link>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-kubesphere-on-gke/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-kubesphere-on-gke/</guid>
      <description>This guide walks you through the steps of deploying KubeSphere on Google Kubernetes Engine.
Prepare a GKE Cluster   A standard Kubernetes cluster in GKE is a prerequisite of installing KubeSphere. Go to the navigation menu and refer to the image below to create a cluster.
  In Cluster basics, select a Master version. The static version 1.15.12-gke.2 is used here as an example.
  In default-pool under Node Pools, define 3 nodes in this cluster.</description>
    </item>
    
    <item>
      <title>Deploy KubeSphere on Huawei CCE</title>
      <link>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-ks-on-huawei-cce/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-ks-on-huawei-cce/</guid>
      <description>This guide walks you through the steps of deploying KubeSphere on Huaiwei CCE.
Preparation for Huawei CCE Create Kubernetes cluster First, create a Kubernetes cluster based on the requirements below.
 KubeSphere 3.0.0 supports Kubernetes 1.15.x, 1.16.x, 1.17.x, and 1.18.x. Select a version and create the cluster, e.g. v1.15.11 or v1.17.9. Ensure the cloud computing network for your Kubernetes cluster works, or use an elastic IP when you use “Auto Create” or “Select Existing”.</description>
    </item>
    
    <item>
      <title>Jobs</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/jobs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/jobs/</guid>
      <description>A Job creates one or more Pods and ensures that a specified number of them successfully terminate. As Pods successfully complete, the Job tracks the successful completions. When a specified number of successful completions is reached, the task (ie, Job) is complete. Deleting a Job will clean up the Pods it created.
A simple case is to create one Job object in order to reliably run one Pod to completion. The Job object will start a new Pod if the first Pod fails or is deleted (for example due to a node hardware failure or a node reboot).</description>
    </item>
    
    <item>
      <title>CronJobs</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/cronjob/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/cronjob/</guid>
      <description>CronJobs are useful for creating periodic and recurring tasks, like running backups or sending emails. CronJobs can also schedule individual tasks at a specific time or interval, such as scheduling a Job for when your cluster is likely to be idle.
For more information, see the official documentation of Kubernetes.
Prerequisites  You need to create a workspace, a project and an account (project-regular). Please refer to Create Workspace, Project, Account and Role if they are not ready yet.</description>
    </item>
    
    <item>
      <title>Deploy KubeSphere on Oracle OKE</title>
      <link>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-kubesphere-on-oke/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-kubernetes/hosted-kubernetes/install-kubesphere-on-oke/</guid>
      <description>This guide walks you through the steps of deploying KubeSphere on Oracle Kubernetes Engine.
Create a Kubernetes Cluster   A standard Kubernetes cluster in OKE is a prerequisite of installing KubeSphere. Go to the navigation menu and refer to the image below to create a cluster.
  In the pop-up window, select Quick Create and click Launch Workflow.
Note
In this example, Quick Create is used for demonstration which will automatically create all the resources necessary for a cluster in Oracle Cloud.</description>
    </item>
    
    <item>
      <title>Routes</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/ingress/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/ingress/</guid>
      <description>Route is the kubernetes Ingress.
A Route provides a way to aggregate services, and you can expose the cluster&amp;rsquo;s internal services to the outside through an externally accessible IP address.
Prerequisites  You need to create a workspace, project and project-regular account. Please refer to the Getting Started with Multi-tenant Management if not yet. You need to sign in with project-admin account and invite project-regular to enter the corresponding project if not yet.</description>
    </item>
    
    <item>
      <title>Container Image Settings</title>
      <link>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/container-image-settings/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/project-user-guide/application-workloads/container-image-settings/</guid>
      <description>When you create Deployments, StatefulSets or DaemonSets, you need to specify a container image. At the same time, KubeSphere provides users with various options to customize workload configurations, such as health check probes, environment variables and start commands. This page illustrates detailed explanations of different properties in Container Image.
Tip
You can enable Edit Mode in the top right corner to see corresponding values in the manifest file (YAML format) of properties on the dashboard.</description>
    </item>
    
    <item>
      <title>Add Kafka as Receiver (aka Collector)</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/log-collections/add-kafka-as-receiver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/log-collections/add-kafka-as-receiver/</guid>
      <description>KubeSphere supports using Elasticsearch, Kafka and Fluentd as log receivers. This doc will demonstrate:
 Deploy strimzi-kafka-operator and then create a Kafka cluster and a Kafka topic by creating Kafka and KafkaTopic CRDs. Add Kafka log receiver to receive logs sent from Fluent Bit. Verify whether the Kafka cluster is receiving logs using Kafkacat.  Prerequisite Before adding a log receiver, you need to enable any of the logging, events or auditing components following Enable Pluggable Components.</description>
    </item>
    
    <item>
      <title>Add New Nodes</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/cluster-operation/add-new-nodes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/cluster-operation/add-new-nodes/</guid>
      <description>After you use KubeSphere for a certain period of time, it is likely that you need to scale out your cluster with an increasing number of workloads. In this case, KubeSphere provides script to add new nodes to the cluster. Fundamentally, the operation is based on Kubelet&amp;rsquo;s registration mechanism. In other words, the new nodes will automatically join the existing Kubernetes cluster.
Tip
From v3.0.0, you can use the brand-new installer KubeKey to scale the master and worker node from a sing-node (all-in-one) cluster.</description>
    </item>
    
    <item>
      <title>Import Aliyun ACK Cluster</title>
      <link>https://cnimages.github.io/website/docs/multicluster-management/import-cloud-hosted-k8s/import-aliyun-ack/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/multicluster-management/import-cloud-hosted-k8s/import-aliyun-ack/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>Import AWS EKS Cluster</title>
      <link>https://cnimages.github.io/website/docs/multicluster-management/import-cloud-hosted-k8s/import-aws-eks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/multicluster-management/import-cloud-hosted-k8s/import-aws-eks/</guid>
      <description>In this section, we are going to show you how to import EKS to KubeSphere using direct connection method.
Note
If you are planning to import EKS using agent connection, then you can skip this section and follow the doc step by step. Amazon EKS doesn&amp;rsquo;t provide a built-in kubeconfig file as a standard kubeadm cluster did. But you can create kubeconfig automatically by referring to this doc. The generated kubeconfig will be like the following,</description>
    </item>
    
    <item>
      <title>Import Kubeadm Kubernetes Cluster</title>
      <link>https://cnimages.github.io/website/docs/multicluster-management/import-on-prem-k8s/import-kubeadm-k8s/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/multicluster-management/import-on-prem-k8s/import-kubeadm-k8s/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>Remove a Cluster from KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/multicluster-management/remove-cluster/kubefed-in-kubesphere/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/multicluster-management/remove-cluster/kubefed-in-kubesphere/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>Remove Nodes</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/cluster-operation/remove-nodes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/cluster-operation/remove-nodes/</guid>
      <description>Cordon a Node Marking a node as unschedulable prevents the scheduler from placing new pods onto that node while not affecting existing Pods on the node. This is useful as a preparatory step before a node reboot or other maintenance.
To mark a node unschedulable, you can choose Cluster Nodes under Nodes from the left menu, find a node you want to remove from the cluster, and click the Cordon button.</description>
    </item>
    
    <item>
      <title>Add Fluentd as Receiver (aka Collector)</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/log-collections/add-fluentd-as-receiver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/log-collections/add-fluentd-as-receiver/</guid>
      <description>KubeSphere supports using Elasticsearch, Kafka and Fluentd as log receivers. This doc will demonstrate:
 How to deploy Fluentd as deployment and create corresponding service and configmap. How to add Fluentd as a log receiver to receive logs sent from Fluent Bit and then output to stdout. How to verify if Fluentd receives logs successfully.  Prerequisites  Before adding a log receiver, you need to enable any of the logging, events or auditing components following Enable Pluggable Components.</description>
    </item>
    
    <item>
      <title>Uninstalling KubeSphere and Kubernetes</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/uninstalling/uninstalling-kubesphere-and-kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/uninstalling/uninstalling-kubesphere-and-kubernetes/</guid>
      <description>You can delete the cluster by the following command.
Tip
Uninstall will remove KubeSphere and Kubernetes from your machine. This operation is irreversible and does not have any backup. Please be cautious with the operation.  If you started with the quickstart (all-in-one):  ./kk delete cluster  If you started with the advanced mode (created with a configuration file):  ./kk delete cluster [-f config-sample.yaml] </description>
    </item>
    
    <item>
      <title>Configure Booster for Installation</title>
      <link>https://cnimages.github.io/website/docs/installing-on-linux/faq/configure-booster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-linux/faq/configure-booster/</guid>
      <description>If you have trouble downloading images from dockerhub.io, it is highly recommended that you configure a registry mirror (i.e. booster) beforehand to speed up downloads. You can refer to the official documentation of Docker or follow the steps below.
Get Booster URL To configure the booster, you need a registry mirror address. See the following example to see how you can get a booster URL from Alibaba Cloud.
 Log in the console of Alibaba Cloud and enter &amp;ldquo;container registry&amp;rdquo; in the search bar.</description>
    </item>
    
    <item>
      <title>FAQ</title>
      <link>https://cnimages.github.io/website/docs/installing-on-kubernetes/faq/faq1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/installing-on-kubernetes/faq/faq1/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://cnimages.github.io/website/docs/multicluster-management/introduction/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/multicluster-management/introduction/overview/</guid>
      <description>Today, it&amp;rsquo;s very common for organizations to run and manage multiple Kubernetes clusters across different cloud providers or infrastructures. As each Kubernetes cluster is a relatively self-contained unit, the upstream community is struggling to research and develop a multi-cluster management solution. That said, Kubernetes Cluster Federation (KubeFed for short) may be a possible approach among others.
The most common use cases of multi-cluster management include service traffic load balancing, development and production isolation, decoupling of data processing and data storage, cross-cloud backup and disaster recovery, flexible allocation of computing resources, low latency access with cross-region services, and vendor lock-in avoidance.</description>
    </item>
    
    <item>
      <title>Kubernetes Federation in KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/multicluster-management/introduction/kubefed-in-kubesphere/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/multicluster-management/introduction/kubefed-in-kubesphere/</guid>
      <description>The multi-cluster feature relates to the network connection among multiple clusters. Therefore, it is important to understand the topological relations of clusters as the workload can be reduced.
Before you use the multi-cluster feature, you need to create a Host Cluster (hereafter referred to as H Cluster), which is actually a KubeSphere cluster with the multi-cluster feature enabled. All the clusters managed by the H Cluster are called Member Cluster (hereafter referred to as M Cluster).</description>
    </item>
    
    <item>
      <title>All-in-one Installation on Linux</title>
      <link>https://cnimages.github.io/website/docs/quick-start/all-in-one-on-linux/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/quick-start/all-in-one-on-linux/</guid>
      <description>For those who are new to KubeSphere and looking for a quick way to discover the platform, the all-in-one mode is your best choice to get started. It features rapid deployment and hassle-free configuration installation with KubeSphere and Kubernetes all provisioned on your machine.
Step 1: Prepare Linux Machine See the requirements for hardware and operating system shown below. To get started with all-in-one installation, you only need to prepare one host according to the following requirements.</description>
    </item>
    
    <item>
      <title>Direct Connection</title>
      <link>https://cnimages.github.io/website/docs/multicluster-management/enable-multicluster/direct-connection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/multicluster-management/enable-multicluster/direct-connection/</guid>
      <description>Prerequisites You have already installed at least two KubeSphere clusters. Please refer to Installing on Linux or Installing on Kubernetes if they are not ready yet.
Note
Multi-cluster management requires Kubesphere to be installed on the target clusters. If you have an existing cluster, you can deploy KubeSphere on it with a minimal installation so that it can be imported. See Minimal KubeSphere on Kubernetes for details. Direct Connection If the kube-apiserver address of Member Cluster (hereafter referred to as M Cluster) is accessible on any node of the Host Cluster (hereafter referred to as H Cluster), you can adopt Direction Connection.</description>
    </item>
    
    <item>
      <title>Agent Connection</title>
      <link>https://cnimages.github.io/website/docs/multicluster-management/enable-multicluster/agent-connection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/multicluster-management/enable-multicluster/agent-connection/</guid>
      <description>Prerequisites You have already installed at least two KubeSphere clusters. Please refer to Installing on Linux or Installing on Kubernetes if they are not ready yet.
Note
Multi-cluster management requires Kubesphere to be installed on the target clusters. If you have an existing cluster, you can deploy KubeSphere on it with a minimal installation so that it can be imported. See Minimal KubeSphere on Kubernetes for details. Agent Connection The component Tower of KubeSphere is used for agent connection.</description>
    </item>
    
    <item>
      <title>Retrieve KubeConfig</title>
      <link>https://cnimages.github.io/website/docs/multicluster-management/enable-multicluster/retrieve-kubeconfig/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/multicluster-management/enable-multicluster/retrieve-kubeconfig/</guid>
      <description>Prerequisites You have a KubeSphere cluster.
Explore KubeConfig File Go to $HOME/.kube, and check the file in the directory where, normally, a file named config exists. Use the following command to retrieve the KubeConfig file:
cat $HOME/.kube/config apiVersion: v1 clusters: - cluster: certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJd01EZ3dPREE1hqaVE3NXhwbGFQNUgwSm5ySk5peTBacFh6QWxjYzZlV2JlaXJ1VgpUbmZUVjZRY3pxaVcrS3RBdFZVbkl4MCs2VTgzL3FiKzdINHk2RnA0aVhUaDJxRHJ6Qkd4dG1UeFlGdC9OaFZlCmhqMHhEbHVMOTVUWkRjOUNmSFgzdGZJeVh5WFR3eWpnQ2g1RldxbGwxVS9qVUo2RjBLVVExZ1pRTFp4TVJMV0MKREM2ZFhvUGlnQ3BNaVRPVXl5SVNhWUVjYVNBMEo5VWZmSGd4ditVcXVleTc0cEM2emszS0lOT2tGMkI1MllxeApUa09OT2VkV2hDUExMZkUveVJqeGw1aFhPL1Z4REFaVC9HQ1Y1a0JZN0toNmRhendmUllOa21IQkhDMD0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=hqaVE3NXhwbGFQNUgwSm5ySk5peTBacFh6QWxjYzZlV2JlaXJ1VgpUbmZUVjZRY3pxaVcrS3RBdFZVbkl4MCs2VTgzL3FiKzdINHk2RnA0aVhUaDJxRHJ6Qkd4dG1UeFlGdC9OaFZlCmhqMHhEbHVMOTVUWkRjOUNmSFgzdGZJeVh5WFR3eWpnQ2g1RldxbGwxVS9qVUo2RjBLVVExZ1pRTFp4TVJMV0MKREM2ZFhvUGlnQ3BNaVRPVXl5SVNhWUVjYVNBMEo5VWZmSGd4ditVcXVleTc0cEM2emszS0lOT2tGMkI1MllxeApUa09OT2VkV2hDUExMZkUveVJqeGw1aFhPL1Z4REFaVC9HQ1Y1a0JZN0toNmRhendmUllOa21IQkhDMD0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= server: https://lb.kubesphere.local:6443 name: cluster.local contexts: - context: cluster: cluster.local user: kubernetes-admin name: kubernetes-admin@cluster.local current-context: kubernetes-admin@cluster.local kind: Config preferences: {} users: - name: kubernetes-admin user: client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM4akNDQWRxZ0F3SUJBZ0lJRzd5REpscVdjdTh3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TURBNE1EZ3dPVEkzTXpkYUZ3MHlNVEE0TURnd09USTNNemhhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnsOTJBUkJDNTRSR3BsZ3VmCmw5a0hPd0lEQVFBQm95Y3dKVEFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFEQ2FUTXNBR1Vhdnhrazg0NDZnOGNRQUJpSmk5RTZiREV5TwphRnJubC8reGRzRmgvOTFiMlNpM3ZwaHFkZ2k5bXRYWkhhaWI5dnQ3aXdtSEFwbGQxUkhBU25sMFoxWFh1dkhzCmMzcXVIU0puY3dmc3JKT0I4UG9NRjVnaG10a0dPV3g0M2RHTTNHQnpGTVJ4ZGcrNmttNjRNUGhneXl6NTJjYUoKbzhPajNja1Uzd1NWNkxvempRcFVaUnZHV25qQjEwUXFPWXBtQUk4VCtlZkxKZzhuY0drK3V3UUVTeXBYWExpYwoxWVQ2QkFJeFhEK2tUUU1hOFhjdUhHZzlWRkdsUm9yK1EvY3l0S3RDeHVncFlxQ2xvbHVpckFUUnpsemRXamxYCkVQaHVjRWs2UUdIZEpObjd0M2NwRGkzSUdYYXJFdGxQQmFwck9nSGpkOHZVOStpWXdoQT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=TJBUkJDNTRSR3BsZ3VmCmw5a0hPd0lEQVFBQm95Y3dKVEFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFEQ2FUTXNBR1Vhdnhrazg0NDZnOGNRQUJpSmk5RTZiREV5TwphRnJubC8reGRzRmgvOTFiMlNpM3ZwaHFkZ2k5bXRYWkhhaWI5dnQ3aXdtSEFwbGQxUkhBU25sMFoxWFh1dkhzCmMzcXVIU0puY3dmc3JKT0I4UG9NRjVnaG10a0dPV3g0M2RHTTNHQnpGTVJ4ZGcrNmttNjRNUGhneXl6NTJjYUoKbzhPajNja1Uzd1NWNkxvempRcFVaUnZHV25qQjEwUXFPWXBtQUk4VCtlZkxKZzhuY0drK3V3UUVTeXBYWExpYwoxWVQ2QkFJeFhEK2tUUU1hOFhjdUhHZzlWRkdsUm9yK1EvY3l0S3RDeHVncFlxQ2xvbHVpckFUUnpsemRXamxYCkVQaHVjRWs2UUdIZEpObjd0M2NwRGkzSUdYYXJFdGxQQmFwck9nSGpkOHZVOStpWXdoQT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= client-key-data: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlFcEFJQkFBS0NBUUVBeXBLWkdtdmdiSHdNaU9pVU80UHZKZXB2MTJaaE1yRUIxK2xlVnM0dHIzMFNGQ0p1Ck8wc09jL2lUNmFuWEJzUU1XNDF6V3hwV1B5elkzWXlUWEJMTlIrM01pWTl2SFhUeWJ6eitTWnNlTzVENytHL3MKQnR5NkovNGpJb2pZZlRZNTFzUUxyRVJydStmVnNGeUU0U2dXbE1HYWdqV0RIMFltM0VJsOTJBUkJDNTRSR3BsZ3VmCmw5a0hPd0lEQVFBQm95Y3dKVEFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFEQ2FUTXNBR1Vhdnhrazg0NDZnOGNRQUJpSmk5RTZiREV5TwphRnJubC8reGRzRmgvOTFiMlNpM3ZwaHFkZ2k5bXRYWkhhaWI5dnQ3aXdtSEFwbGQxUkhBU25sMFoxWFh1dkhzCmMzcXVIU0puY3dmc3JKT0I4UG9NRjVnaG10a0dPV3g0M2RHTTNHQnpGTVJ4ZGcrNmttNjRNUGhneXl6NTJjYUoKbzhPajNja1Uzd1NWNkxvempRcFVaUnZHV25qQjEwUXFPWXBtQUk4VCtlZkxKZzhuY0drK3V3UUVTeXBYWExpYwoxWVQ2QkFJeFhEK2tUUU1hOFhjdUhHZzlWRkdsUm9yK1EvY3l0S3RDeHVncFlxQ2xvbHVpckFUUnpsemRXamxYCkVQaHVjRWs2UUdIZEpObjd0M2NwRGkzSUdYYXJFdGxQQmFwck9nSGpkOHZVOStpWXdoQT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=Ygo3THE3a2tBMURKNTBld2pMUTNTd1Yxd2p6N2ZjeDYvbzUwRnJnK083dEJMVVdQNTNHaDQ1VjJpUEp2NkdPYk1uCjhIWElmem83cW5XRFQvU20ybW5HbitUdVY4THdLVWFXL2wya3FkRUNnWUVBcS9zRmR1RDk2Z3VoT2ZaRnczcWMKblZGekNGQ3JsMkUvVkdYQy92SmV1WnJLQnFtSUtNZFI3ajdLWS9WRFVlMnJocVd6MFh2Wm9Sa1FoMkdwWkdIawpDd3NzcENKTVl4L0hETTVaWlBvcittb1J6VE5HNHlDNGhTRGJ2VEFaTmV1VTZTK1hzL1JSTDJ6WnUwemNQQXk1CjJJRVgwelFpZ1JzK3VzS3Jkc1FVZXZrQ2dZQUUrQUNWeDJnMC94bmFsMVFJNmJsK3Y2TDJrZVJtVGppcHB4Wm0KS1JEd2xnaXpsWGxsTjhyQmZwSGNiK1ZnZ282anN2eHFrb0pkTEhBLzFDME5IMWVuS1NoUTlpZVFpeWNsZngwdQpKOE1oeW1JM0RBZUg1REJyOG1rZ0pwNnJwUXNBc1paYmVhOHlLTzV5eVdCYTN6VGxOVnQvNDRibGg5alpnTWNMCjNyUXFVUUtCZ1FETVlXdEt2S0hOQllXV0p5enFERnFPbS9qY3Z3andvcURibUZVMlU3UGs2aUdNVldBV3VYZ3cKSm5qQWtES01GN0JXSnJRUjR6RHVoQlhvQVMxWVhiQ2lGd2hTcXVjWGhFSGlwQ3Nib0haVVRtT1pXUUh4Vlp4bQowU1NiRXFZU2MvZHBDZ1BHRk9IaW1FdUVic05kc2JjRmRETDQyODZHb0psQUxCOGc3VWRUZUE9PQotLS0tLUVORCBSU0EgUFJJVkFURSBLRVktLS0tLQo= </description>
    </item>
    
    <item>
      <title>Minimal KubeSphere on Kubernetes</title>
      <link>https://cnimages.github.io/website/docs/quick-start/minimal-kubesphere-on-k8s/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/quick-start/minimal-kubesphere-on-k8s/</guid>
      <description>In addition to installing KubeSphere on a Linux machine, you can also deploy it on existing Kubernetes clusters directly. This QuickStart guide walks you through the general steps of completing a minimal KubeSphere installation on Kubernetes. For more information, see Installing on Kubernetes.
Note
 To install KubeSphere on Kubernetes, your Kubernetes version must be 1.15.x, 1.16.x, 1.17.x, or 1.18.x; Make sure your machine meets the minimal hardware requirement: CPU &amp;gt; 1 Core, Memory &amp;gt; 2 G; A default Storage Class in your Kubernetes cluster needs to be configured before the installation; The CSR signing feature is activated in kube-apiserver when it is started with the --cluster-signing-cert-file and --cluster-signing-key-file parameters.</description>
    </item>
    
    <item>
      <title>Create Workspace, Project, Account and Role</title>
      <link>https://cnimages.github.io/website/docs/quick-start/create-workspace-and-project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/quick-start/create-workspace-and-project/</guid>
      <description>Objective This guide demonstrates how to create roles and user accounts which are required for the following tutorials. Meanwhile, you will learn how to create projects and DevOps projects within your workspace where your workloads are running. After this tutorial, you will become familiar with KubeSphere multi-tenant management system.
Prerequisites KubeSphere needs to be installed in your machine.
Estimated Time About 15 minutes.
Architecture The multi-tenant system of KubeSphere features three levels of hierarchical structure which are cluster, workspace and project.</description>
    </item>
    
    <item>
      <title>Deploy Bookinfo and Manage Traffic</title>
      <link>https://cnimages.github.io/website/docs/quick-start/deploy-bookinfo-to-k8s/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/quick-start/deploy-bookinfo-to-k8s/</guid>
      <description>Istio, as an open-source service mesh solution, provides powerful features of traffic management for microservices. Here is the introduction of traffic management from the official website of Istio:
Istio’s traffic routing rules let you easily control the flow of traffic and API calls between services. Istio simplifies configuration of service-level properties like circuit breakers, timeouts, and retries, and makes it easy to set up important tasks like A/B testing, canary rollouts, and staged rollouts with percentage-based traffic splits.</description>
    </item>
    
    <item>
      <title>Compose and Deploy WordPress</title>
      <link>https://cnimages.github.io/website/docs/quick-start/wordpress-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/quick-start/wordpress-deployment/</guid>
      <description>WordPress Introduction WordPress is a free and open-source content management system written in PHP, allowing users to build their own websites. A complete WordPress application includes the following Kubernetes objects with MySQL serving as the backend database.
Objective This tutorial demonstrates how to create an application (WordPress as an example) in KubeSphere and access it outside the cluster.
Prerequisites An account project-regular is needed with the role operator assigned in one of your projects (the user has been invited to the project).</description>
    </item>
    
    <item>
      <title>Enable Pluggable Components</title>
      <link>https://cnimages.github.io/website/docs/quick-start/enable-pluggable-components/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/quick-start/enable-pluggable-components/</guid>
      <description>This tutorial demonstrates how to enable pluggable components of KubeSphere both before and after the installation. KubeSphere features ten pluggable components which are listed below.
   Configuration Item Corresponding Component Description     alerting KubeSphere alerting system Enable users to customize alerting policies to send messages to receivers in time with different time intervals and alerting levels to choose from.   auditing KubeSphere audit log system Provide a security-relevant chronological set of records, recording the sequence of activities that happen in the platform, initiated by different tenants.</description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://cnimages.github.io/website/docs/pluggable-components/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/pluggable-components/overview/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>KubeSphere App Store</title>
      <link>https://cnimages.github.io/website/docs/pluggable-components/app-store/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/pluggable-components/app-store/</guid>
      <description>What is KubeSphere App Store As an open-source and app-centric container platform, KubeSphere provides users with a Helm-based app store for application lifecycle management on the back of OpenPitrix, an open-source web-based system to package, deploy and manage different types of apps. KubeSphere App Store allows ISVs, developers and users to upload, test, deploy and release apps with just several clicks in a one-stop shop.
Internally, KubeSphere App Store can serve as a place for different teams to share data, middleware, and office applications.</description>
    </item>
    
    <item>
      <title>KubeSphere DevOps System</title>
      <link>https://cnimages.github.io/website/docs/pluggable-components/devops/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/pluggable-components/devops/</guid>
      <description>What is KubeSphere DevOps System KubeSphere DevOps System is designed for CI/CD workflows in Kubernetes. Based on Jenkins, it provides one-stop solutions to help both development and Ops teams build, test and publish apps to Kubernetes in a straight-forward way. It also features plugin management, Binary-to-Image (B2I), Source-to-Image (S2I), code dependency caching, code quality analysis, pipeline logging, etc.
The DevOps system offers an enabling environment for users as apps can be automatically released to the same platform.</description>
    </item>
    
    <item>
      <title>KubeSphere Auditing Logs</title>
      <link>https://cnimages.github.io/website/docs/pluggable-components/auditing-logs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/pluggable-components/auditing-logs/</guid>
      <description>What are KubeSphere Auditing Logs KubeSphere Auditing Log System provides a security-relevant chronological set of records documenting the sequence of activities related to individual users, managers, or other components of the system. Each request to KubeSphere generates an event that is then written to a webhook and processed according to a certain rule.
For more information, see Auditing Log Query.
Enable Auditing Logs before Installation Installing on Linux When you implement multi-node installation KubeSphere on Linux, you need to create a configuration file, which lists all KubeSphere components.</description>
    </item>
    
    <item>
      <title>KubeSphere Events</title>
      <link>https://cnimages.github.io/website/docs/pluggable-components/events/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/pluggable-components/events/</guid>
      <description>What are KubeSphere Events KubeSphere events allow users to keep track of what is happening inside a cluster, such as node scheduling status and image pulling result. They will be accurately recorded with the specific reason, status and message displayed in the web console. To query events, users can quickly launch the web Toolkit and enter related information in the search bar with different filters (e.g keyword and project) available. Events can also be archived to third-party tools, such as Elasticsearch, Kafka or Fluentd.</description>
    </item>
    
    <item>
      <title>KubeSphere Logging System</title>
      <link>https://cnimages.github.io/website/docs/pluggable-components/logging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/pluggable-components/logging/</guid>
      <description>What is KubeSphere Logging System KubeSphere provides a powerful, holistic and easy-to-use logging system for log collection, query and management. It covers logs at varied levels, including tenants, infrastructure resources, and applications. Users can search logs from different dimensions, such as project, workload, Pod and keyword. Compared with Kibana, the tenant-based logging system of KubeSphere features better isolation and security among tenants as each tenant can only view his or her own logs.</description>
    </item>
    
    <item>
      <title>Logging</title>
      <link>https://cnimages.github.io/website/docs/pluggable-components/faq/logging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/pluggable-components/faq/logging/</guid>
      <description>How to change the log store to external elasticsearch and shut down the internal elasticsearch How to change the log store to elasticsearch with X-Pack Security enabled How to modify log data retention days Cannot find out logs from workloads on some nodes in Toolbox The log view page in Toolbox gets stuck in loading Toolbox shows no log record today Internal Server Error when viewing logs in Toolbox How to make KubeSphere only collect logs from specified workloads  How to change the log store to external elasticsearch and shut down the internal elasticsearch If you are using KubeSphere internal elasticsearch and want to change it to your external alternate, follow the guide below.</description>
    </item>
    
    <item>
      <title>KubeSphere Service Mesh</title>
      <link>https://cnimages.github.io/website/docs/pluggable-components/service-mesh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/pluggable-components/service-mesh/</guid>
      <description>What is KubeSphere Service Mesh On the basis of Istio, KubeSphere Service Mesh visualizes microservices governance and traffic management. It features a powerful toolkit including circuit breaking, blue-green deployment, canary release, traffic mirroring, distributed tracing, observability and traffic control. Developers can easily get started with Service Mesh without any code hacking, with the learning curve of Istio greatly reduced. All features of KubeSphere Service Mesh are designed to meet users&amp;rsquo; demand for their business.</description>
    </item>
    
    <item>
      <title>Monitoring</title>
      <link>https://cnimages.github.io/website/docs/pluggable-components/faq/monitoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/pluggable-components/faq/monitoring/</guid>
      <description>How to access KubeSphere Prometheus console Host port 9100 conflict caused by node exporter Conflicts with preexisting prometheus operator How to modify monitoring data retention days No monitoring data for kube-scheduler and kube-controller-manager No monitoring data for the last few minutes No monitoring data for both nodes and the control plane Prometheus produces error log: opening storage failed, no such file or directory  How to access KubeSphere Prometheus console KubeSphere monitoring engine is powered by Prometheus.</description>
    </item>
    
    <item>
      <title>KubeSphere Alerting and Notification</title>
      <link>https://cnimages.github.io/website/docs/pluggable-components/alerting-notification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/pluggable-components/alerting-notification/</guid>
      <description>What are KubeSphere Alerting and Notification Alerting and Notification are two important building blocks of observability, closely related monitoring and logging. The alerting system in KubeSphere, coupled with the proactive failure notification system, allows users to know activities of interest based on alert policies. When a predefined threshold of a certain metric is reached, an alert will be sent to preconfigured recipients, the notification method of which can be set by yourself, including Email, WeChat Work and Slack.</description>
    </item>
    
    <item>
      <title>Network Policy</title>
      <link>https://cnimages.github.io/website/docs/pluggable-components/network-policy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/pluggable-components/network-policy/</guid>
      <description>What is Network Policy Starting from v3.0.0, users can configure network policies of native Kubernetes in KubeSphere. Network Policies are an application-centric construct, enabling you to specify how a pod is allowed to communicate with various network entities over the network. With network policies, users can achieve network isolation within the same cluster, which means firewalls can be set up between certain instances (pods).
Note
 Please make sure that the CNI network plugin used by the cluster supports Network Policies before you enable it.</description>
    </item>
    
    <item>
      <title>Overview</title>
      <link>https://cnimages.github.io/website/docs/upgrade/upgrade-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/upgrade/upgrade-overview/</guid>
      <description>Kubernetes KubeSphere v3.0.0 is compatible with Kubernetes 1.15.x, 1.16.x, 1.17.x and 1.18.x:
  If your KubeSphere v2.1.x is installed on Kubernetes 1.15.x+, you can choose to only upgrade KubeSphere to v3.0.0 or upgrade Kubernetes (to a higher version) and KubeSphere (to v3.0.0) at the same time.
  If your KubeSphere v2.1.x is installed on Kubernetes 1.14.x, you have to upgrade Kubernetes (to 1.15.x+) and KubeSphere (to v3.0.0 ) at the same time.</description>
    </item>
    
    <item>
      <title>Upgrade with KubeKey</title>
      <link>https://cnimages.github.io/website/docs/upgrade/upgrade-with-kubekey/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/upgrade/upgrade-with-kubekey/</guid>
      <description>KubeKey is recommended for users whose KubeSphere and Kubernetes were both deployed by KubeSphere Installer. If your Kubernetes cluster was provisioned by yourself or cloud providers, please refer to Upgrade with ks-installer.
Prerequisites   You need to have a KubeSphere cluster running version 2.1.1.
Warning
If your KubeSphere version is v2.1.0 or earlier, please upgrade to v2.1.1 first.   Download KubeKey.
  Download KubeKey from GitHub Release Page or use the following command directly.</description>
    </item>
    
    <item>
      <title>Upgrade with ks-installer</title>
      <link>https://cnimages.github.io/website/docs/upgrade/upgrade-with-ks-installer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/upgrade/upgrade-with-ks-installer/</guid>
      <description>ks-installer is recommended for users whose Kubernetes clusters were not set up via KubeSphere Installer, but hosted by cloud vendors. This tutorial is for upgrading KubeSphere only. Cluster operators are responsible for upgrading Kubernetes themselves beforehand.
Prerequisites   You need to have a KubeSphere cluster running version 2.1.1.
Warning
If your KubeSphere version is v2.1.0 or earlier, please upgrade to v2.1.1 first.   Make sure you read Release Notes For 3.</description>
    </item>
    
    <item>
      <title>Changes after Upgrade</title>
      <link>https://cnimages.github.io/website/docs/upgrade/what-changed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/upgrade/what-changed/</guid>
      <description>This section covers the changes after upgrade for existing settings in previous versions. If you want to know all the new features and enhancements in KubeSphere 3.0.0, see Release Notes for 3.0.0 directly.
Access Control The definition of custom roles has been simplified. Some closely-related permission items have been aggregated into permission groups. Custom roles will not change during the upgrade and can be used directly after the upgrade if they conform to new policy rules for authorization assignment.</description>
    </item>
    
    <item>
      <title>FAQ</title>
      <link>https://cnimages.github.io/website/docs/upgrade/upgrade-faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/upgrade/upgrade-faq/</guid>
      <description>How to upgrade Qingcloud CSI after upgrading? Currently Qingcloud CSI will not be upgraded by KubeKey. You can run the following command to upgrade CSI manually after finishing KubeSphere upgrade:
git clone https://github.com/yunify/qingcloud-csi.gitcd qingcloud-csi/git checkout v1.1.1kubectl delete -f deploy/disk/kubernetes/releases/qingcloud-csi-disk-v1.1.1.yamlkubectl delete sc csi-qingcloudhelm repo add test https://charts.kubesphere.io/testhelm install test/csi-qingcloud --name-template csi-qingcloud --namespace kube-system \--set config.qy_access_key_id=KEY,config.qy_secret_access_key=SECRET,config.zone=ZONE,sc.type=2Wait until csi controller and daemonset are running
$ kubectl get po -n kube-system | grep csicsi-qingcloud-controller-56979d46cb-qk9ck 5/5 Running 0 24hcsi-qingcloud-node-4s8n5 2/2 Running 0 24hcsi-qingcloud-node-65dqn 2/2 Running 0 24hcsi-qingcloud-node-khk49 2/2 Running 0 24hcsi-qingcloud-node-nz9q9 2/2 Running 0 24hcsi-qingcloud-node-pxr56 2/2 Running 0 24hcsi-qingcloud-node-whqhk 2/2 Running 0 24hThen run the following command to check csi image version is 1.</description>
    </item>
    
    <item>
      <title>Alerting Policy (Node Level)</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/cluster-wide-alerting-and-notification/alerting-policy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/cluster-wide-alerting-and-notification/alerting-policy/</guid>
      <description>Objective KubeSphere provides alert policies for nodes and workloads. This guide demonstrates how you can create alert policies for nodes in the cluster and configure mail notifications. See Alerting Policy (Workload Level) to learn how to configure alert policies for workloads.
Prerequisites  KubeSphere Alerting and Notification needs to be enabled. Mail Server needs to be configured.  Hands-on Lab Task 1: Create an Alert Policy   Log in the console with one account granted the role platform-admin.</description>
    </item>
    
    <item>
      <title>Alerting Message (Node Level)</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/cluster-wide-alerting-and-notification/alerting-message/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/cluster-wide-alerting-and-notification/alerting-message/</guid>
      <description>Alert messages record detailed information of alerts triggered based on alert rules, including monitoring targets, alert policies, recent notifications and comments.
Prerequisites You have created a node-level alert policy and received alert notifications of it. If it is not ready, please refer to Alert Policy (Node Level) to create one first.
Hands-on Lab Task 1: View Alert Message   Log in the console with one account granted the role platform-admin.</description>
    </item>
    
    <item>
      <title>Log Query</title>
      <link>https://cnimages.github.io/website/docs/toolbox/log-query/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/toolbox/log-query/</guid>
      <description>The logs of applications and systems can help you better understand what is happening inside your cluster and workloads. The logs are particularly useful for debugging problems and monitoring cluster activities. KubeSphere provides a powerful and easy-to-use logging system which offers users the capabilities of log collection, query and management from the perspective of tenants. The tenant-based logging system is much more useful than Kibana since different tenants can only view their own logs, leading to better security.</description>
    </item>
    
    <item>
      <title>Mail Server</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/mail-server/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/cluster-settings/mail-server/</guid>
      <description>Objective This guide demonstrates email notification settings (customized settings supported) for alert policies. You can specify user email addresses to receive alert messages.
Prerequisites KubeSphere Alerting and Notification needs to be enabled.
Hands-on Lab   Log in the web console with one account granted the role platform-admin.
  Click Platform in the top left corner and select Clusters Management.
  Select a cluster from the list and enter it (If you do not enable the multi-cluster feature, you will directly go to the Overview page).</description>
    </item>
    
    <item>
      <title>Customizing Platform Information</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/platform-settings/customize-basic-information/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/platform-settings/customize-basic-information/</guid>
      <description>TBD</description>
    </item>
    
    <item>
      <title>Event Query</title>
      <link>https://cnimages.github.io/website/docs/toolbox/events-query/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/toolbox/events-query/</guid>
      <description>Objective Kubernetes events provide insight into what is happening inside a cluster, based on which KubeSphere adds longer historical query and aggregation capabilities, and also supports event query for tenant isolation. This guide demonstrates how you will do multi-level, fine-grained event queries to track the state of your components.
Prerequisites  KubeSphere Events needs to be enabled.  Hands-on Lab   The event query function is available for all users.</description>
    </item>
    
    <item>
      <title>Receive and Customize Auditing Logs</title>
      <link>https://cnimages.github.io/website/docs/toolbox/auditing/auditing-receive-customize/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/toolbox/auditing/auditing-receive-customize/</guid>
      <description>KubeSphere Auditing Logs provide a security-relevant chronological set of records documenting the sequence of activities that have affected the system by individual users, administrators, or other components of the system. Each request to KubeSphere generates an event that is then written to a webhook and processed according to a certain rule. The event will be ignored, stored, or generate an alert based on different rules.
Enable KubeSphere Auditing Logs To enable auditing logs, see KubeSphere Auditing Logs.</description>
    </item>
    
    <item>
      <title>Auditing Rule</title>
      <link>https://cnimages.github.io/website/docs/toolbox/auditing/auditing-rule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/toolbox/auditing/auditing-rule/</guid>
      <description>An auditing rule defines the policy for processing auditing logs. KubeSphere Auditing Logs provide users with two CRD rules (archiving-rule and alerting-rule) for customization.
After you enable KubeSphere Auditing Logs, log in the console with an account of platform-admin role. In CRDs on the Cluster Management page, input rules.auditing.kubesphere.io in the search bar. Click the result Rule as below and you can see the two CRD rules.
Below are examples of part of the rules.</description>
    </item>
    
    <item>
      <title>Auditing Log Query</title>
      <link>https://cnimages.github.io/website/docs/toolbox/auditing/auditing-query/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/toolbox/auditing/auditing-query/</guid>
      <description>KubeSphere supports the query of auditing logs among isolated tenants. In this tutorial, you will learn how to use the query function, including the interface, search parameters and detail pages.
Prerequisites You need to enable KubeSphere Auditing Logs.
Enter Query Dashboard  The query function is available for all users. Log in the console with any account, hover over the Toolbox in the lower right corner and select Auditing Operating.  Note</description>
    </item>
    
    <item>
      <title>Cluster Shutdown and Restart</title>
      <link>https://cnimages.github.io/website/docs/cluster-administration/shut-down-and-restart-cluster-gracefully/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/cluster-administration/shut-down-and-restart-cluster-gracefully/</guid>
      <description>This document describes the process of gracefully shutting down your cluster and how to restart it. You might need to temporarily shut down your cluster for maintenance reasons.
Warning
Shutting down a cluster is very dangerous. You must fully understand the operation and its consequences. Please make an etcd backup before you proceed. Usually, it is recommended to maintain your nodes one by one instead of restarting the whole cluster. Prerequisites  Take an etcd backup prior to shutting down a cluster.</description>
    </item>
    
    <item>
      <title>Web Kubectl</title>
      <link>https://cnimages.github.io/website/docs/toolbox/web-kubectl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/toolbox/web-kubectl/</guid>
      <description>The Kubernetes command-line tool, kubectl, allows you to run commands on Kubernetes clusters. You can use kubectl to deploy applications, inspect and manage cluster resources, and view logs.
KubeSphere provides web kubectl on the console for user convenience. By default, in the current version, only the account granted the platform-admin role (such as the default account admin) has the permission to use web kubectl for cluster resource operation and management.</description>
    </item>
    
    <item>
      <title>History</title>
      <link>https://cnimages.github.io/website/docs/toolbox/history/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/toolbox/history/</guid>
      <description>When you work in multiple workspaces or projects, your web browser will record the latest path you visited. You can check your history using F1, Win+K, or Command +K, which helps you quickly switch between the resources you access.</description>
    </item>
    
    <item>
      <title>Questions about KubeSphere Console</title>
      <link>https://cnimages.github.io/website/docs/faq/console-faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/faq/console-faq/</guid>
      <description>What kind of browsers does KubeSphere support?
In general, KubeSphere console supports major web browsers including Chrome, Firefox, Safari, Opera, and Edge. You only need to consider the supported versions of these browsers listed in the green box of the table below:</description>
    </item>
    
    <item>
      <title>Telemetry in KubeSphere</title>
      <link>https://cnimages.github.io/website/docs/faq/telemetry/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/faq/telemetry/</guid>
      <description>Telemetry collects aggregate information about the size of KubeSphere clusters installed, KubeSphere and Kubernetes versions, components enabled, cluster running time, error logs, etc. KubeSphere promises that the information is only used by the KubeSphere community to improve products and will not be shared with any third parties.
What Information Is Collected  External network IP Download date Kubernetes version KubeSphere version Kubernetes cluster size The type of the operating system Installer error logs Components enabled The running time of Kubernetes clusters The running time of KubeSphere clusters Cluster ID Machine ID  Disable Telemetry Telemetry is enabled by default when you install KubeSphere, while you also have the option to disable it either before or after the installation.</description>
    </item>
    
    <item>
      <title>A Container Platform: What is the Value of KubeSphere</title>
      <link>https://cnimages.github.io/website/blogs/value-of-kubesphere/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/blogs/value-of-kubesphere/</guid>
      <description>A Promising Newcomer As a promising newcomer of the cloud native family, KubeSphere has gained widespread recognition among its users and developers since it joined the open source community nearly two years ago. This article illustrates the position and value of KubeSphere from scratch in a straightforward way and sheds light on why different teams have chosen KubeSphere.
For Enterprises KubeSphere is a multi-tenant container platform built on Kubernetes with applications at its core.</description>
    </item>
    
    <item>
      <title>Anchnet</title>
      <link>https://cnimages.github.io/website/case/anchnet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/case/anchnet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Aqara</title>
      <link>https://cnimages.github.io/website/case/aqara/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/case/aqara/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Benlai</title>
      <link>https://cnimages.github.io/website/case/benlai/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/case/benlai/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cloud Native Observability: Log Management</title>
      <link>https://cnimages.github.io/website/conferences/logging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/conferences/logging/</guid>
      <description>As logs often contain very valuable information, log management represents an important part of cloud native observability. Logs feature a standard output (stdout) in containers and Kubernetes, which is different from physical machines or virtual machines. This means the collection, analysis and management of logs at the platform level can be carried out in a unified fashion, which demonstrates the unique value of logs. This article introduces a major solution to log management (EFK) in the cloud native area, FluentBit Operator developed by the KubeSphere team and some practices of KubeSphere in multi-tenant log management.</description>
    </item>
    
    <item>
      <title>contribution request</title>
      <link>https://cnimages.github.io/website/contribution/request/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/contribution/request/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Development Practices of CSI Storage Plugins - Part Ⅰ</title>
      <link>https://cnimages.github.io/website/conferences/csi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/conferences/csi/</guid>
      <description>Many users will transfer their apps to Kubernetes, where storage underlies applications. As users deploy their apps on the Kubernetes, some existing storage plugins are unable to satisfy the growing needs in terms of both diversity and functionality. This is why we need to accelerate the development of new storage plugins, and integrate QingCloud storage services with Kubernetes and KubeSphere.
Kubernetes Storage Plugin Classification In this article, we will focus on the development practices of Kubernetes storage plugins based on CSI.</description>
    </item>
    
    <item>
      <title>Embrace KubeSphere Spanish Community and European Market: Geko and KubeSphere Build Partnership</title>
      <link>https://cnimages.github.io/website/news/kubesphere-geko-partnership/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/news/kubesphere-geko-partnership/</guid>
      <description>July 22, 2020 - KubeSphere and Geko are pleased to announce a joint partnership to deliver outstanding value to KubeSphere users in Spain, and further to Europe. As part of KubeSphere’s endeavor to bring the fruitful result of open source to users around the world, this marks a great milestone for the container platform as we are embracing a more diversified and vibrant community.
Spain is home to one of the most active open source communities in Europe.</description>
    </item>
    
    <item>
      <title>Huaxia Bank</title>
      <link>https://cnimages.github.io/website/case/huaxia-bank/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/case/huaxia-bank/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jenkins System Settings</title>
      <link>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/jenkins-setting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/docs/devops-user-guide/how-to-use/jenkins-setting/</guid>
      <description>Jenkins is powerful and flexible and it has become the de facto standard for CI/CD workflow. But flexibility comes at a price: because in addition to the Jenkins itself, many plugins require some system-level configuration to get the job done.
KubeSphere DevOps is based on Jenkins for containerized CI/CD workflow functionality. To provide users with a schedulable Jenkins environment, KubeSphere uses Configuration-as-Code for Jenkins system settings, which requires the user to log in to Jenkins Dashboard and reload after KubeSphere modifies the configuration file.</description>
    </item>
    
    <item>
      <title>Kubernetes Multi-cluster Deployment: Federation and KubeSphere</title>
      <link>https://cnimages.github.io/website/blogs/multi-cluster-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/blogs/multi-cluster-deployment/</guid>
      <description>Scenarios for Multi-cluster Deployment As the container technology and Kubernetes see a surge in popularity among their users, it is not uncommon for enterprises to run multiple clusters for their business. In general, here are the main scenarios where multiple clusters can be adopted.
High Availability You can deploy workloads on multiple clusters by using a global VIP or DNS to send requests to corresponding backend clusters. When a cluster malfunctions or fails to handle requests, the VIP or DNS records can be transferred to a health cluster.</description>
    </item>
    
    <item>
      <title>KubeSphere 3.0.0 GA: Born for Hybrid Cloud Apps</title>
      <link>https://cnimages.github.io/website/news/kubesphere-3.0.0-ga-announcement/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/news/kubesphere-3.0.0-ga-announcement/</guid>
      <description>August 31, 2020 - KubeSphere open source community today announces the General Availability of KubeSphere 3.0.0!
KubeSphere 3.0.0 highlights key features for hybrid clouds. It is born for multi-cloud operation, multi-cluster deployment, multi-team cooperation and multi-tenant management, boasting powerful enhancements for cluster management, observability, storage and network management, multi-tenant security, App Store, installation and more. It provides better user experiences as it becomes more interactive and responsive. KubeSphere 3.0.0 is by far the most important version ever released.</description>
    </item>
    
    <item>
      <title>KubeSphere Api Documents</title>
      <link>https://cnimages.github.io/website/api/crd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/api/crd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>KubeSphere Api Documents</title>
      <link>https://cnimages.github.io/website/api/kubesphere/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/api/kubesphere/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Maxnerva</title>
      <link>https://cnimages.github.io/website/case/maxnerva/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/case/maxnerva/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Monitoring Kubernetes Control Plane using KubeSphere</title>
      <link>https://cnimages.github.io/website/blogs/monitoring-k8s-control-plane/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/blogs/monitoring-k8s-control-plane/</guid>
      <description>Introduction to Kubernetes Control Plane In a Kubernetes cluster, there are two machines roles including master nodes and worker nodes. The master node runs the Kubernetes control plane, which is responsible for the management of the worker nodes, makes scheduling decisions, and implements changes to drive the cluster to a desired state. The worker nodes, as the name implies, they run the workloads and Pod on them.
As is shown in the graph, there are four components running in the Kubernetes control plane, each of them is critical for running a healthy Kubernetes cluster, they act as the different roles within the cluster:</description>
    </item>
    
    <item>
      <title>partner request</title>
      <link>https://cnimages.github.io/website/partner/request/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/partner/request/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Porter: An Innovative Cloud Native Service Proxy in CNCF Landscape</title>
      <link>https://cnimages.github.io/website/blogs/porter-in-cncf-landscape/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/blogs/porter-in-cncf-landscape/</guid>
      <description>Porter, a load balancer developed for bare metal Kubernetes clusters, was officially included in CNCF Landscape last week. This marks a great milestone for its parent project KubeSphere as it continues to deliver cloud native technologies to the wider community.
Cloud Native Computing Foundation, or CNCF, was built for the establishment of sustainable ecosystems for cloud native software. Its Interactive Landscape is dynamically generated, serving as a technology roadmap for various industries.</description>
    </item>
    
    <item>
      <title>Porter: An Open Source Load Balancer for Kubernetes in a Bare Metal Environment</title>
      <link>https://cnimages.github.io/website/conferences/porter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/conferences/porter/</guid>
      <description>We know that we can use the service of LoadBalancer in the Kubernetes cluster to expose backend workloads externally. Cloud providers often offer cloud LoadBalancer plugins, which requires the cluster to be deployed on a specific IaaS platform. However, many enterprise users often deploy the Kubernetes cluster on bare metal, especially when it is used for the production environment. For the local bare metal cluster, Kubernetes does not provide LB implementation.</description>
    </item>
    
    <item>
      <title>Radore and KubeSphere: Walk into the Future of Hybrid Cloud and Build Ecosystem Together</title>
      <link>https://cnimages.github.io/website/news/kubesphere-radore-partnership/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/news/kubesphere-radore-partnership/</guid>
      <description>June 30, 2020 - In the online launch event of KubeSphere v3.0, Ray Zhou, leader of KubeSphere project, officially announced the exciting news of establishing a strong partnership with Radore, a Turkish enterprise with over 14 years of expertise. The cooperation aims to provide diversified cloud computing solutions for both Turkish companies and individuals, laying a solid foundation for KubeSphere to go global in the future.
“In fact, it is Radore that came to us first.</description>
    </item>
    
    <item>
      <title>Spanish and Traditional Chinese Localization Available in KubeSphere Web Console</title>
      <link>https://cnimages.github.io/website/news/spanish-traditional-chinese-available/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/news/spanish-traditional-chinese-available/</guid>
      <description>The web console of KubeSphere v3.0 now supports the localization of Spanish and Traditional Chinese. In User Settings, you can select the language of web console in the drop-down menu.
Here, we would like to thank Geko Cloud, our Spanish partner that provides the Spanish localization. This serves as a great start for the cooperation between KubeSphere and Geko as the two sides promise to further develop the Spanish community. With a brand-new Spanish web console, KubeSphere aims to create better user experiences for users around the world who prefer Spanish UI.</description>
    </item>
    
    <item>
      <title>TiDB on KubeSphere: Using Cloud-Native Distributed Database on Kubernetes Platform Tailored for Hybrid Cloud</title>
      <link>https://cnimages.github.io/website/blogs/tidb-on-kubesphere-using-qke/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/blogs/tidb-on-kubesphere-using-qke/</guid>
      <description>In a world where Kubernetes has become the de facto standard to build application services that span multiple containers, running a cloud-native distributed database represents an important part of the experience of using Kubernetes. In this connection, TiDB, a cloud-native, open-source NewSQL database that supports Hybrid Transactional and Analytical Processing (HTAP) workloads, meets those needs admirably. Its architecture is suitable for Kubernetes, and it is MySQL compatible. TiDB also features horizontal scalability, strong consistency, and high availability.</description>
    </item>
    
    <item>
      <title>VNG</title>
      <link>https://cnimages.github.io/website/case/vng/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://cnimages.github.io/website/case/vng/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>